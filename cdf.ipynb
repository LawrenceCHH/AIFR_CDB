{"cells":[{"cell_type":"markdown","metadata":{"id":"5eRSxlMFXUTF"},"source":["# Load Model"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"XJEy6_4rXUTJ","outputId":"a343ddbe-7e65-4ad9-801c-2c72a7abe152"},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["# !module load cuda/11.8\n","import os\n","import torch\n","from transformers import AutoConfig, AutoModel, AutoTokenizer\n","import json\n","import pandas as pd\n","from tqdm import tqdm\n","import gc\n","import numpy as np\n","llm_path = r\"/workspace/LLM/chatglm-6b\"\n","\n","\n","def load_ori_glm1(llm_path=\"/workspace/LLM/chatglm-6b\"):\n","    # config = AutoConfig.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True, pre_seq_len=1024, output_hidden_states=True, output_attentions = True)\n","    # config = AutoConfig.from_pretrained(\"THUDM/chatglm-6b-int4\", trust_remote_code=True, output_hidden_states=True, output_attentions = True)\n","    # model = AutoModel.from_pretrained(\"THUDM/chatglm-6b-int4\", config=config, trust_remote_code=True).half().cuda()\n","    config = AutoConfig.from_pretrained(llm_path, trust_remote_code=True, output_hidden_states=True, output_attentions = True)\n","    # model = AutoModel.from_pretrained(llm_path, config=config, trust_remote_code=True).half().cuda()\n","    model = AutoModel.from_pretrained(llm_path, config=config, trust_remote_code=True).quantize(4).half().cuda()\n","    model = model.eval()\n","    tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\n","    return model\n","def load_ori_glm2(llm_path=\"/workspace/LLM/chatglm2-6b\"):\n","    config = AutoConfig.from_pretrained(llm_path, trust_remote_code=True, output_hidden_states=True, output_attentions = True)\n","    model = AutoModel.from_pretrained(llm_path, config=config, trust_remote_code=True).quantize(4).half().cuda()\n","    model = model.eval()\n","    return model\n","\n","def load_glm_checkpoint(checkpoint_path, llm_path):\n","\n","    # 载入Tokenizer\n","    # tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\n","    # config = AutoConfig.from_pretrained(llm_path, trust_remote_code=True, pre_seq_len=1024)\n","\n","    # tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\n","    config = AutoConfig.from_pretrained(llm_path, trust_remote_code=True, pre_seq_len=1024, output_hidden_states=True, output_attentions = True)\n","\n","    # # model = AutoModel.from_pretrained(\"/content/drive/MyDrive/share_p/20230416_chatglm6b_model\", config=config, trust_remote_code=True)\n","    model = AutoModel.from_pretrained(llm_path, config=config, trust_remote_code=True)\n","    print(\"Parameter Merging!\")\n","    prefix_state_dict = torch.load(os.path.join(checkpoint_path, \"pytorch_model.bin\"))\n","\n","    new_prefix_state_dict = {}\n","    for k, v in prefix_state_dict.items():\n","        if k.startswith(\"transformer.prefix_encoder.\"):\n","            new_prefix_state_dict[k[len(\"transformer.prefix_encoder.\"):]] = v\n","    model.transformer.prefix_encoder.load_state_dict(new_prefix_state_dict)\n","    print(\"Model Quantizationing!\")\n","    model = model.quantize(4)\n","    model = model.half().cuda()\n","    model.transformer.prefix_encoder.float()\n","    model = model.eval()\n","    print(\"Model Loaded!\")\n","    return model\n","\n","\n","def read_json(json_path):\n","    with open(json_path, \"r\", encoding=\"utf-8-sig\") as json_file:\n","        # json_list = json_file.readlines()\n","        json_list = [json.loads(line) for line in json_file]\n","        keys = [key for key in json_list[0].keys()]\n","        print(f\"json length:{len(json_list)}\\njson keys:{keys}\")\n","    return json_list\n","\n","\n","def get_mean_pooling_embedding(input_text, tokenizer, model):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    inputs = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True, return_attention_mask=True, truncation=True, max_length=2048)\n","    inputs = {k:v.to(device) for k,v in inputs.items()}\n","    # print(len(inputs['input_ids'][0]))\n","\n","    with torch.no_grad():\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        outputs = model(**inputs)\n","    # hidden state shape (batch_size, sequence_length, hidden_size)\n","    # (input_tokens_length, 1, 4096)\n","    last_hidden_state = outputs[2][-1]\n","    input_tokens_length = last_hidden_state.shape[0]\n","    # (1, 4096)\n","    embedding = torch.sum(last_hidden_state, 0)\n","    embedding = embedding[0] / input_tokens_length\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    return embedding\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UgWW-vJoXUTL","outputId":"e361af6c-945b-498a-ce75-64d9113d0036"},"outputs":[],"source":["# import gc\n","embedding = None\n","gc.collect()\n","torch.cuda.empty_cache()\n","gc.collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7a5TBQ_eXUTM","outputId":"693e2693-54f8-4d28-e0fc-9d1a617f9f54"},"outputs":[],"source":["# 調整參數區\n","# checkpoint_path = r\"workspace/ptuning/output/20230620_hackson_1000-6b-pt-1024-1e-2/checkpoint-{}\"  #改\n","tokenizer = AutoTokenizer.from_pretrained(\"/workspace/LLM\", trust_remote_code=True)\n","# -----------------------------\n","# merged_model = load_glm_checkpoint(checkpoint_path.format(str(400)))\n","merged_model = load_local_glm()"]},{"cell_type":"markdown","metadata":{"id":"H3njzKVMXUTN"},"source":["# Vector store (ChatGLM)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"executionInfo":{"elapsed":1213,"status":"error","timestamp":1704450839539,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"vWx5nypyXUTN","outputId":"94ced5d7-79ee-476a-cdf1-d4b29ecbd668"},"outputs":[],"source":["import pandas as pd\n","# # Check if csv files are correctly corresponded.\n","e_fee = pd.read_csv('/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_fee_embedding.csv')\n","# 1057180\n","fee = pd.read_csv('/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_fee.csv')\n","\n","print(\"fee_embedding length: \", len(e_fee))\n","print(\"Last data dimension of fee_embedding: \", len(eval(e_fee.iloc[len(e_fee)-1]['embedding'])))\n","print(\"fee ID == fee_embedding ID: \",e_fee.iloc[:len(e_fee)]['Unnamed: 0'].tolist()==fee.iloc[:len(e_fee)]['Unnamed: 0'].tolist())\n","print('\\nLast data of fee_embedding:\\n', e_fee.iloc[len(e_fee)-1])\n","print('\\nSame data of fee:\\n', fee.iloc[len(e_fee)-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d_vmlhxxXUTN","outputId":"b70676ae-f3ae-4b38-83b9-754891d56832"},"outputs":[],"source":["# Store in csv file\n","import numpy as np\n","import faiss\n","from tqdm import tqdm\n","dir_path = '/cluster/home/lawrencechh.cs/cdf_dataset/'\n","target_df_paths = ['/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_fee.csv',\n","                   '/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_opinion.csv',\n","                   '/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_sub.csv']\n","# d = 4096\n","# res = faiss.StandardGpuResources()\n","# save_vector_store_steps = 5000\n","# 20231231 2545/1057180\n","# 20240102 22812/1057180\n","# 20240105 40051/1031823\n","embedding_df_length = 2545 + 22812 + 40051\n","start_index = embedding_df_length\n","for path in target_df_paths:\n","    print(path)\n","    df = pd.read_csv(path)[embedding_df_length:]\n","    # df = pd.read_csv(path)\n","    # df = pd.read_csv(path, nrows=100)\n","\n","    basic_column, category_column, target_column_name = df.columns[0], df.columns[1], df.columns[2]\n","    output_df = pd.DataFrame(columns=[basic_column, category_column, 'embedding'])\n","    output_csv_path = f\"/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_{target_column_name}_embedding.csv\"\n","    if os.path.isfile(output_csv_path) == False:\n","        output_df.to_csv(output_csv_path, index=False)\n","    else:\n","        print(\"File exists.\")\n","    # index_flat = faiss.IndexFlatL2(d)\n","    # gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n","\n","    for i in tqdm(range(len(df))):\n","        input_text = df.iloc[i][target_column_name]\n","        basic_id = df.iloc[i][basic_column]\n","        category_id = df.iloc[i][category_column]\n","        print(df.iloc[i])\n","        break\n","        # print(df.iloc[start_index+i])\n","        # print(len(input_text))\n","        embedding = get_mean_pooling_embedding(input_text, tokenizer, merged_model)\n","        # embedding = embedding.to(\"cpu\").numpy().astype(np.float32).tolist()\n","        embedding = str(embedding.to(\"cpu\").numpy().astype(np.float32).tolist())\n","        output_df.loc[0] = {basic_column: basic_id, category_column: category_id, 'embedding': embedding}\n","        # embedding = np.array(embedding.cpu(), dtype=np.float32)\n","        # index_flat.add(np.array([embedding]))\n","        # gpu_index_flat.add(np.array([embedding]))\n","\n","\n","        # output_df.to_csv(output_csv_path, mode=\"a\", index=False, header=False, encoding=\"utf-8-sig\")\n","\n","\n","        # if i%5==0:\n","        #     output_df = pd.DataFrame(columns=[basic_column, category_column, 'embedding'])\n","            # faiss.write_index(faiss.index_gpu_to_cpu(gpu_index_flat), f\"/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_{target_column_name}.bin\")\n","            # faiss.write_index(index_flat, f\"/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_{target_column_name}.bin\")\n","        gc.collect()\n","        embedding = None\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","\n","    # faiss.write_index(faiss.index_gpu_to_cpu(gpu_index_flat), f\"/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_{target_column_name}.bin\")\n","    # faiss.write_index(index_flat, f\"/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_{target_column_name}.bin\")\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"HlDRWS4MXUTO"},"source":["## Test faiss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cnzj6wPrXUTP","outputId":"7a2edc65-7c71-49af-92f6-9926608588cc"},"outputs":[],"source":["import numpy as np\n","input_text = \"你好\"\n","v = get_mean_pooling_embedding(input_text, tokenizer, merged_model)\n","print(type(v))\n","# output_df = pd.DataFrame(columns=['embedding'])\n","# for i in range(1000):\n","#     # output_df.loc[len(output_df)] = {'embedding': v.detach().cpu().numpy()}\n","#     output_df.loc[len(output_df)] = {'embedding': v.cpu().numpy().astype(np.float32)}\n","    # output_df.loc[len(output_df)] = {'embedding': v.cpu()}\n","# output_df.to_csv('/cluster/home/lawrencechh.cs/cdf_dataset/test_embedding.csv', index_label='index')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jobTbGUoXUTP","outputId":"4940c968-2fc2-4e3e-e1e8-2b28713b7e8d"},"outputs":[],"source":["import faiss # make faiss available\n","# Dimension\n","d = 4096\n","res = faiss.StandardGpuResources()\n","index_flat = faiss.IndexFlatL2(d)\n","# make it into a gpu index\n","gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n","for i in range(1000):\n","    gpu_index_flat.add(np.array([npv]))         # add vectors to the index\n","    if i%500==0:\n","        faiss.write_index(faiss.index_gpu_to_cpu(gpu_index_flat), \"/cluster/home/lawrencechh.cs/cdf_dataset/index.bin\")\n","        print(gpu_index_flat.ntotal)\n","faiss.write_index(faiss.index_gpu_to_cpu(gpu_index_flat), \"/cluster/home/lawrencechh.cs/cdf_dataset/index.bin\")\n","print(gpu_index_flat.ntotal)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LCs_7eXfXUTQ","outputId":"daead87c-2323-4ed3-8a71-fd6eeac75847"},"outputs":[],"source":["index2 = faiss.read_index(\"/cluster/home/lawrencechh.cs/cdf_dataset/index.bin\")\n","gpu_index_flat2 = faiss.index_cpu_to_gpu(res, 0, index2)\n","print(gpu_index_flat2.ntotal)\n","for i in range(1000):\n","    gpu_index_flat2.add(np.array([npv]))         # add vectors to the index\n","    if i%500==0:\n","        faiss.write_index(faiss.index_gpu_to_cpu(gpu_index_flat2), \"/cluster/home/lawrencechh.cs/cdf_dataset/index.bin\")\n","        print(gpu_index_flat2.ntotal)\n","print(gpu_index_flat2.ntotal)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FkrsAapTXUTQ","outputId":"e70e61d9-8aad-4444-d7ec-e5c616a5d605"},"outputs":[],"source":["index2 = faiss.read_index(\"/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_sub.bin\")\n","index2.ntotal\n","index2."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IIQr3fKsXUTQ","outputId":"f7bd7489-fe6c-49ca-d2a6-2954b0f915cc"},"outputs":[],"source":["# # load quantized\n","# input_text = \"你好\"\n","# v = get_mean_pooling_embedding(input_text, tokenizer, merged_model)\n","# print(v)\n","# print(len(v))\n","\n","# input_text = \"天氣如何?\"\n","# v = get_mean_pooling_embedding(input_text, tokenizer, merged_model)\n","# print(v)\n","# print(len(v))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Zs2eqEABXUTR","outputId":"78e5e67e-ae63-4da8-e320-972026528389"},"outputs":[],"source":["# # load ori then quantized\n","# input_text = \"你好\"\n","# v = get_mean_pooling_embedding(input_text, tokenizer, merged_model)\n","# print(v)\n","# print(len(v))\n","\n","# input_text = \"天氣如何?\"\n","# v = get_mean_pooling_embedding(input_text, tokenizer, merged_model)\n","# print(v)\n","# print(len(v))"]},{"cell_type":"markdown","metadata":{},"source":["## Store criminal opinions vector"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import faiss\n","from tqdm import tqdm\n","import numpy as np\n","\n","# # Read target csv\n","# eop_df = pd.read_csv('/workspace/CDB/cdb/static/1222_opinion_sentence_district_embedding.csv')\n","print(len(eop_df))\n","\n","# Dimension\n","d = 4096\n","res = faiss.StandardGpuResources()\n","index_flat = faiss.IndexFlatL2(d)\n","\n","# make it into a gpu index\n","gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index_flat)\n","for i in tqdm(range(len(eop_df))):\n","    # add vectors to the index\n","    tmp_embedding = eval(eop_df.iloc[i]['embedding'])\n","    tmp_embedding = np.array([tmp_embedding])\n","    gpu_index_flat.add(tmp_embedding)         \n","\n","faiss.write_index(faiss.index_gpu_to_cpu(gpu_index_flat), \"/workspace/CDB/cdb/static/1222_opinion_sentence_district_index.bin\")\n","print(gpu_index_flat.ntotal)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["teste = eval(eop_df.iloc[0]['embedding'])\n","teste = np.array([teste])\n","print(teste.shape)"]},{"cell_type":"markdown","metadata":{"id":"ioQCEbIMXUTR"},"source":["# Data of Criminal Database"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XnBcoeSpXUTR","outputId":"b5a0a767-061d-4e80-c37e-ab71106ef1fd"},"outputs":[],"source":["b_ori = pd.read_csv('/cluster/home/lawrencechh.cs/cdf_dataset/output.csv')\n","c_ori = pd.read_csv('/cluster/home/lawrencechh.cs/cdf_dataset/20231204_dic_-001.csv')\n","\n","print(\"output.csv: \", len(b_ori))\n","print(\"20231204_dic_-001.csv\", len(c_ori))\n","tmp_df = b_ori[b_ori['JID'].isin(c_ori['case_num'])]\n","# tmp_df = c_ori[c_ori['case_num'].isin(b_ori['JID'])]\n","print(\"Same Jud: \", len(tmp_df))\n","print(list(b_ori.columns))\n","print(list(c_ori.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":125468,"status":"ok","timestamp":1704786795972,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"lI26OWQXXUTR","outputId":"3159215d-348b-4fb7-9c52-92feff119c96"},"outputs":[],"source":["merged_b = pd.read_csv('/gdrive/MyDrive/研究資料/高院/20231211_categoryID_basic_data.csv')\n","opinion_df = pd.read_csv('/gdrive/MyDrive/研究資料/高院/20231211_category_basic_data_merged_opinion.csv')\n","print(len(merged_b))\n","print(len(merged_b.dropna()))\n","tmp_df = merged_b[merged_b['count'].isna()]\n","print(len(tmp_df))\n","print(tmp_df.iloc[0])\n","# print(merged_b.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evjtjUUVNHiM"},"outputs":[],"source":["print(merged_b.columns)\n","print(opinion_df.columns)\n","print()\n","print(merged_b.iloc[0])\n","print()\n","\n","print(opinion_df.iloc[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FU_-ADeXUTR","outputId":"1659b944-b193-4be4-9691-931042ca1291"},"outputs":[],"source":["import pandas as pd\n","from tqdm import tqdm\n","# merged_df = pd.read_csv('/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged.csv')\n","print('merged_df length: ', len(merged_df))\n","print('merged_df columns: ', merged_df.columns)\n","\n","target_columns = list(merged_df.columns[-4:-1])\n","print(target_columns)\n","for target_col in target_columns:\n","    target_list = merged_df[target_col].tolist()\n","    target_num = 0\n","    for target in tqdm(target_list):\n","        # print(target)\n","        # print(type(target))\n","        if type(target)==str:\n","            target_num+=len(eval(target))\n","        else:\n","            continue\n","    print(f\"{target_col} numbers: \", target_num)\n","    target_df_path = f'/cluster/home/lawrencechh.cs/cdf_dataset/20231211_category_basic_data_merged_{target_col}.csv'\n","    target_df = pd.read_csv(target_df_path)\n","    print(f\"20231211_category_basic_data_merged_{target_col}.csv length: \", len(target_df))\n","    print(f'{target_col} numbers == merged_{target_col}.csv length: ', target_num==len(target_df))\n"]},{"cell_type":"markdown","metadata":{"id":"UwdGQRM4XUTR"},"source":["# Extract 法官、檢察官 (附件前方)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146909,"status":"ok","timestamp":1704980533769,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"2yc-vnNjXZAt","outputId":"b88de9d1-497e-4435-f125-4e099c89ed67"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","dir_path = '/gdrive/MyDrive/研究資料/高院'\n","import pandas as pd\n","import re\n","from tqdm import tqdm\n","import random\n","merged_b = pd.read_csv(dir_path + '/20231211_categoryID_basic_data.csv')\n","print(merged_b.columns)\n","\n","print('merged_b length', len(merged_b))\n","print('matched data length', len(merged_b.dropna()))"]},{"cell_type":"markdown","metadata":{"id":"lZGgC5DhSpZt"},"source":["## Extract prosecutor"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30842,"status":"ok","timestamp":1704980564607,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"iqENlk92SySp","outputId":"cf3c3be2-0cee-41c6-fd90-c13715060d55"},"outputs":[],"source":["# Shorten judgments length\n","extracted_length = []\n","\n","def locating_judge_and_prosecutor_texts_lists(input_list):\n","    patterns = [r'據上論[斷|結].+?書記官.+?\\r?\\n?',\n","            r'作\\s*成\\s*本\\s*判\\s*決。.+?書記官.+?[ |\\r]*\\n',\n","            r'判決如主文。.+?書記官.+?\\r?\\n?',\n","            r'本案經檢察官.+?書記官.+?\\r?\\n?',\n","            r'應\\s*予\\s*駁\\s*回\\s*。.+?書記官.+?[ |\\r]*\\n',\n","            r'刑事第.+庭.+?書記官.+?[ |\\r]*\\n'\n","            ]\n","\n","    error_signs = ['\\u3000', '\\u30005', '\\u3000111', '\\u30004', '\\u300011', '\\u30003', '\\u300024', '&nbsp;', '\\u3000110', '\\u300012', '\\u300030', ' ']\n","    matched_indices = [[] for _ in range(len(patterns))]\n","    empty_list = []\n","    print('matched_indices', matched_indices)\n","    for i in tqdm(range(len(input_list))):\n","        jud = input_list[i][1]\n","        input_list_id = input_list[i][0]\n","        # ---------------------------\n","        for sign in error_signs:\n","            jud = jud.replace(sign, '')\n","        for rule_index, pattern in enumerate(patterns):\n","            extracted_list = re.findall(pattern, jud, re.DOTALL)\n","            try:\n","                extracted_text_length = len(extracted_list[0])\n","\n","                if extracted_text_length<=1000:\n","                # empty_list length: 68\n","                # rules match list length: [112850, 657, 1524, 1234, 38, 149]\n","                  matched_indices[rule_index].append([input_list_id, extracted_text_length, extracted_list[0]])\n","                else:\n","                  continue\n","\n","                break\n","            except:\n","                continue\n","        if extracted_list == []:\n","            empty_list.append(i)\n","    # [matched_indices[rule_index][[input_list_index, extracted_text_length, extracted_text],...], empty_list]\n","    return [matched_indices, empty_list]\n","\n","juds_list = list(zip(merged_b['Unnamed: 0'].tolist(), merged_b['JFULL'].tolist()))\n","extracted_list = locating_judge_and_prosecutor_texts_lists(juds_list)\n","\n","# Sorted list according to length\n","for rule_index, rule_matched_list in enumerate(extracted_list[0]):\n","  extracted_list[0][rule_index] = sorted(rule_matched_list, key=lambda x:x[1], reverse=True)\n","\n","print('empty_list length:', len(extracted_list[1]))\n","print('rules match list length:', [len(rule_list) for rule_list in extracted_list[0]])\n","# extracted_length = sorted(extracted_length, reverse=True)\n","# print(extracted_length[:10])\n","\n","\n","# Locate prosecutor\n","def locate_prosectuor_texts_lists(re_extracted_list):\n","  prosecutor_rules = [\n","      [r'判決如主文。.*?中華民國', True],\n","      [r'本*[案|件][經|由].+?。', True],\n","      # [112266, 413]\n","      # 171\n","  ]\n","  matched_list = [[] for _ in range(len(prosecutor_rules))]\n","  not_matched_list = []\n","\n","  for data_index in tqdm(range(len(re_extracted_list))):\n","    for rule_index, rule in enumerate(prosecutor_rules):\n","      text_replaced = rule[1]\n","      text = re_extracted_list[data_index][1]\n","      re_extracted_list_index = re_extracted_list[data_index][0]\n","      if text_replaced:\n","        text = text.replace('\\r', '').replace('\\n', '').replace(' ', '')\n","\n","      re_text = re.findall(rule[0], text, re.DOTALL)\n","\n","      if len(re_text) > 0:\n","        matched_list[rule_index].append([re_extracted_list_index, len(re_text[0]), re_text[0]])\n","        break\n","      else:\n","        continue\n","    if len(re_text) == 0:\n","      text_before_year = re.findall(r'.+?中華民國', re_extracted_list[data_index][1].replace('\\r', '').replace('\\n', '').replace(' ', ''), re.DOTALL)[0]\n","      text_before_year = text_before_year.strip('中華民國')\n","      # not_matched_list.append([data_index, extracted_list[0][0][data_index][2]])\n","      not_matched_list.append([re_extracted_list_index, len(text_before_year), text_before_year])\n","  return [matched_list, not_matched_list]\n","  print('\\n', [len(dlist) for dlist in matched_list])\n","  print(len(not_matched_list))\n","input_list = [[data[0], data[2]] for data in extracted_list[0][0]]\n","second_extracted_list = locate_prosectuor_texts_lists(input_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1863,"status":"ok","timestamp":1704980810504,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"fSqz5O77wMfg","outputId":"c2809806-b2a8-4d7e-f37b-297a8184a5d3"},"outputs":[],"source":["# Test function\n","print(len(extracted_list))\n","print(len(extracted_list[0]))\n","print(len(extracted_list[0][0]))\n","print(len(extracted_list[0][1]))\n","# [0 matched_list 1 empty_list][rule_index][data_index]\n","extracted_list[0][0][0]\n","\n","\n","input_list = [[data[0], data[2]] for data in extracted_list[0][0]]\n","second_extracted_list = locate_prosectuor_texts_lists(input_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":730,"status":"ok","timestamp":1704981166530,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"gZ6KZSC6xpNq","outputId":"62b29d13-6dee-43d4-fded-0ff275d54b35"},"outputs":[],"source":["print(len(second_extracted_list))\n","print(len(second_extracted_list[0]))\n","print(len(second_extracted_list[0][0]))\n","print(len(second_extracted_list[0][1][0]))\n","second_extracted_list[0][0]"]},{"cell_type":"markdown","metadata":{"id":"hNUITuztq-jN"},"source":["## NER extract names"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51749,"status":"ok","timestamp":1704981004531,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"Tc9DzCFVNVoa","outputId":"6f3bb515-a641-4f43-fc9a-ce615ecb6c11"},"outputs":[],"source":["import jieba\n","import jieba.posseg as psg\n","def find_prosecutor_names(input_list):\n","    not_names = ['應依']\n","    result_list = []  # Create a new list to store the results\n","    for list_index in tqdm(range(len(input_list))):\n","      text = input_list[list_index][2]\n","      data_index = input_list[list_index][0]\n","      seg_list = psg.cut(text)\n","      names = []\n","      for item in seg_list:\n","        if item.word in not_names:\n","          continue\n","        elif item.flag == 'nr' or item.flag == 'nrfg':\n","          names.append(item.word)\n","      result_list.append([data_index, text, names])  # Append the result to the new list\n","    return result_list\n","\n","# name_list = find_prosecutor_names(no_prosecutor)\n","name_list = find_prosecutor_names(second_extracted_list[0][1])\n","name_list"]},{"cell_type":"markdown","metadata":{"id":"zSq-5NMLvvSg"},"source":["## (Dropped) Shorten judgments length"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63869,"status":"ok","timestamp":1704854555976,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"mXkcC98EXUTS","outputId":"cdff6239-d078-4975-abba-7f3b60729e1c"},"outputs":[],"source":["extracted_length = []\n","\n","def get_re_and_empty_list(src_df):\n","    # unicode_pattern = r'\\\\u[0-9A-Fa-f]+'\n","    # unicode_pattern = r'\\u3000.*'\n","    # unicode_pattern = r'[\\u3000-\\u4000+]'\n","    # jud = re.sub(unicode_pattern, '', jud)\n","    # ---------------------------\n","    # error_signs = ['\\u3000', '\\u30005', '\\u3000111', '\\u30004', '\\u300011', '\\u30003', '\\u300024', '&nbsp;', '\\u3000110', '\\u300012', '\\u300030', '\\r', '\\n', ' ']\n","    # pattern = r'中華民國\\d+年\\d+月\\d+日(.*)?中華民國\\d+年\\d+月\\d+日'\n","    # ---------------------------\n","    # error_signs = ['\\u3000', '\\u30005', '\\u3000111', '\\u30004', '\\u300011', '\\u30003', '\\u300024', '&nbsp;', '\\u3000110', '\\u300012', '\\u300030']\n","    # pattern = r'中 *華 *民 *國 *\\d+ *年 *\\d+ *月 *\\d+ *日(.*)?中 *華 *民 *國 *\\d+ *年 *\\d+ *月 *\\d+ *日'\n","    # ---------------------------\n","        # for sign in error_signs:\n","    #     jud = jud.replace(sign, '')\n","    # ---------------------------\n","    # patterns = [r'據上論[斷|結].+?書記官.+?\\n',\n","    #             r'作成本判決。.+?書記官.+?\\n'\n","    #             ]\n","    # # empty_list length: 22984\n","    # # rules match list length: [92950, 595]\n","    # ---------------------------\n","    # # Recommendation\n","    # patterns = [r'據上論[斷|結].+?書記官.+?\\r?\\n?',\n","    #             r'作成本判決。.+?書記官.+?\\r?\\n?',\n","    #             r'判決如主文。.+?書記官.+?\\r?\\n?',\n","    #             r'本案經檢察官.+?書記官.+?\\r?\\n?',\n","    #             ]\n","    # # empty_list length: 17903\n","    # # rules match list length: [95560, 595, 1226, 1245]\n","    # ---------------------------\n","    patterns = [r'據上論[斷|結].+?書記官.+?\\r?\\n?',\n","                r'作\\s*成\\s*本\\s*判\\s*決。.+?書記官.+?[ |\\r]*\\n',\n","                r'判決如主文。.+?書記官.+?\\r?\\n?',\n","                r'本案經檢察官.+?書記官.+?\\r?\\n?',\n","                r'應\\s*予\\s*駁\\s*回\\s*。.+?書記官.+?[ |\\r]*\\n',\n","                r'刑事第.+庭.+?書記官.+?[ |\\r]*\\n'\n","                ]\n","    # empty_list length: 17703\n","    # rules match list length: [95560, 657, 1226, 1209, 35, 139]\n","    # ---------------------------\n","    # patterns = [r'據上論[斷|結].+?書記官',\n","    #             # r'作\\s*成\\s*本\\s*判\\s*決。.+?書記官.+?[ |\\r]*\\n',\n","    #             # r'判決如主文。.+?書記官.+?\\r?\\n?',\n","    #             # r'本案經檢察官.+?書記官.+?\\r?\\n?',\n","    #             # r'應\\s*予\\s*駁\\s*回\\s*。.+?書記官.+?[ |\\r]*\\n',\n","    #             # r'刑事第.+庭.+?書記官.+?[ |\\r]*\\n'\n","    #             ]\n","    # error_signs = ['\\u3000', '\\u30005', '\\u3000111', '\\u30004', '\\u300011', '\\u30003', '\\u300024', '&nbsp;', '\\u3000110', '\\u300012', '\\u300030', '\\r', '\\n', ' ']\n","    error_signs = ['\\u3000', '\\u30005', '\\u3000111', '\\u30004', '\\u300011', '\\u30003', '\\u300024', '&nbsp;', '\\u3000110', '\\u300012', '\\u300030', ' ']\n","    matched_indices = [[] for _ in range(len(patterns))]\n","    empty_list = []\n","    print('matched_indices', matched_indices)\n","    for i in tqdm(range(len(src_df))):\n","        jud = src_df.iloc[i]['JFULL']\n","        # ---------------------------\n","        for sign in error_signs:\n","            jud = jud.replace(sign, '')\n","        for rule_index, pattern in enumerate(patterns):\n","            extracted_list = re.findall(pattern, jud, re.DOTALL)\n","            try:\n","                extracted_text_length = len(extracted_list[0])\n","\n","                if extracted_text_length<=1000:\n","                # empty_list length: 68\n","                # rules match list length: [112850, 657, 1524, 1234, 38, 149]\n","                  matched_indices[rule_index].append([i, extracted_text_length, extracted_list[0]])\n","                else:\n","                  continue\n","\n","                break\n","            except:\n","                continue\n","        if extracted_list == []:\n","            empty_list.append(i)\n","\n","    return [matched_indices, empty_list]\n","\n","extracted_list = get_re_and_empty_list(merged_b)\n","\n","# Sorted list according to length\n","for rule_index, rule_matched_list in enumerate(extracted_list[0]):\n","  extracted_list[0][rule_index] = sorted(rule_matched_list, key=lambda x:x[1], reverse=True)\n","\n","print('empty_list length:', len(extracted_list[1]))\n","print('rules match list length:', [len(rule_list) for rule_list in extracted_list[0]])\n","# extracted_length = sorted(extracted_length, reverse=True)\n","# print(extracted_length[:10])"]},{"cell_type":"markdown","metadata":{"id":"nKTGWhvlv9qw"},"source":["## (Dropped) Find exact entity (檢察官, 法官)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1178,"status":"ok","timestamp":1704854557141,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"cGDQ41LUvsfj","outputId":"dad9201b-9ed3-45c4-ba48-14ba7a123a93"},"outputs":[],"source":["\n","prosecutor_rules = [\n","    [r'判決如主文。.*?中華民國', True],\n","    [r'本*[案|件][經|由].+?。', True],\n","    # [112266, 413]\n","    # 171\n","]\n","prosecutor = [[] for _ in range(len(prosecutor_rules))]\n","no_prosecutor = []\n","for data_index in tqdm(range(len(extracted_list[0][0]))):\n","\n","  for rule_index, rule in enumerate(prosecutor_rules):\n","    text_replaced = rule[1]\n","    text = extracted_list[0][0][data_index][2]\n","    if text_replaced:\n","      text = text.replace('\\r', '').replace('\\n', '').replace(' ', '')\n","\n","    re_text = re.findall(rule[0], text, re.DOTALL)\n","\n","    if len(re_text) > 0:\n","      prosecutor[rule_index].append([data_index, re_text[0]])\n","      break\n","    else:\n","      continue\n","  if len(re_text) == 0:\n","    text_before_year = re.findall(r'.+?中華民國', extracted_list[0][0][data_index][2].replace('\\r', '').replace('\\n', '').replace(' ', ''), re.DOTALL)[0]\n","    text_before_year = text_before_year.strip('中華民國')\n","    # no_prosecutor.append([data_index, extracted_list[0][0][data_index][2]])\n","    no_prosecutor.append([data_index, text_before_year])\n","\n","print('\\n', [len(dlist) for dlist in prosecutor])\n","print(len(no_prosecutor))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":362,"status":"ok","timestamp":1704819832243,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"nviA0XTt-en4","outputId":"5b3d6011-89f8-4e13-ebb9-10051abec26d"},"outputs":[],"source":["# sorted([[len(text[1]), text[0], text[1]] for text in prosecutor[0]], reverse=True)\n","sorted([[len(text[1]), text[0], text[1]] for text in no_prosecutor], reverse=True)\n","# sorted([[len(text[1]), text[0], text[1]] for text in prosecutor[1]], reverse=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SrIZdkLW0aQO"},"outputs":[],"source":["檢察官黃怡君到庭\n","檢察官鄭仙杏提起公訴\n","檢察官謝志明、侯詠琪提起公訴，檢察官謝名冠到庭執行\\r\\n職務\n","檢察官洪國朝提起公訴，檢察官丑○○到庭執行職務。\n","檢察官許月雲到庭執行職務。\n","檢察官何宗霖提起公訴，檢察官吳祚延到庭執行職務。\n","檢察官王亮欽提起公訴，檢察官張慧瓊到庭執行職務。\n","檢察官曲鴻煜提起公訴，檢察官洪政和提起上訴，檢察官\\r\\n周穎宏到庭執行職務。\\\n","\n","\n","檢察官劉孟昕提起公訴，檢察官羅建勛到庭執行職務。\n","\n","檢察官顏郁山提起公訴，檢察官李松諺提起上訴，檢察官\\r\\n陳建弘到庭執行職務。\n","檢察官周欣蓓偵查起訴，由檢察官楊秀琴在本審到庭實行\\r\\n公訴。\n","檢察官賴穎穎偵查起訴，於檢察官張家維提起上訴後，由\\r\\n檢察官沈明倫在本審到庭實行公訴。\n","\n","A案經檢察官陳昭蓉提起公訴，檢察官吳淑娟追加起訴及移送併\\r\\n辦；B案經檢察官朱啟仁提起公訴，均經檢察官蘇南桓到庭執行\\r\\n職務。\n","\n","本案由檢察官陳映蓁、吳欣恩提起公訴，由檢察官王亞樵到庭執\\r\\n行職務。\n","\n","本案由臺灣桃園地方檢察署檢察官鍾信一偵查起訴、檢察官蔡宜\\r\\n均上訴；臺灣高等檢察署檢察官楊四猛到庭執行職務。\\r\\n\n","\n","[939,\n"," '據上論結，應依刑事訴訟法第369第1項前段、第364條、第30\\r\\n3條第5款、第307條，判決如主文。\\r\\n中華民國106年5月9日\\r\\n刑事第四庭審判長法官惠光霞\\r\\n法官王憲義\\r\\n法官李東柏\\r\\n以上正本證明與原本無異。\\r\\n檢察官如不服本判決應於收受本判決後10日內向本院提出上訴書\\r\\n狀，其未敘述上訴理由者，並得於提起上訴後10日內向本院補提\\r\\n理由書狀（均須按他造當事人之人數附繕本）「切勿逕送上級法\\r\\n院」。\\r\\n中華民國106年5月9日\\r\\n書記官洪']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1704728497601,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"rnncbkZpjh4a","outputId":"1d2f6ee9-b5ee-474b-98b1-cc9f9d09b437"},"outputs":[],"source":["# # Check re text over 1000\n","# over_1000 = []\n","# for rule_index in range(len(extracted_list[0])):\n","#   for data_index in tqdm(range(len(extracted_list[0][rule_index]))):\n","#     if extracted_list[0][rule_index][data_index][1]>1000:\n","#       over_1000.append(extracted_list[0][rule_index][data_index][0])\n","# print('\\n', len(over_1000))\n","\n","# # Check single text content\n","# rule_index = 5\n","# data_index = 35\n","# extracted_list[0][rule_index][data_index]\n","\n","# # Randomly select data\n","random_rule_index = random.choice(range(len(extracted_list[0])))\n","random_data_index = random.choice(range(len(extracted_list[0][random_rule_index])))\n","print(f'random_rule_index: {random_rule_index}\\nrandom_data_index: {random_data_index}\\n')\n","extracted_list[0][random_rule_index][random_data_index]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi-VCi6uXUTS","outputId":"34abeebc-f8e4-433e-8161-f6af13bcff9b"},"outputs":[],"source":["target_index = extracted_list[1][1]\n","jud = merged_b.iloc[target_index]['JFULL']\n","url = 'https://judgment.judicial.gov.tw/EXPORTFILE/reformat.aspx?type=JD&id={}&lawpara=&ispdf=1'.format(merged_b.iloc[target_index]['JID'])\n","url2 = 'https://judgment.judicial.gov.tw/FJUD/data.aspx?ty=JD&id={}'.format(merged_b.iloc[target_index]['JID'])\n","print(merged_b.iloc[target_index]['JID'])\n","print(url)\n","print(url2)\n","error_signs = ['\\u3000', '\\u30005', '\\u3000111', '\\u30004', '\\u300011', '\\u30003', '\\u300024', '&nbsp;', '\\u3000110', '\\u300012', '\\u300030', '\\r', '\\n', ' ']\n","for sign in error_signs:\n","    jud = jud.replace(sign, '')\n","# jud.replace(' ', \"\").replace('\\r', \"\").replace('\\n', \"\")\n","jud\n","\n","# larger500 = [length for length in extracted_length if length > 500]\n","# print(len(larger500))\n","\n","\n","# pattern = r'據上論[斷|結].+?書記官.+?\\n'\n","# pattern = r'作\\s*成\\s*本\\s*判\\s*決。.+?書記官.+\\s*'\n","# pattern = r'應\\s*予\\s*駁\\s*回\\s*。.+?書記官.+\\s*'\n","# pattern = r'刑事第.+庭.+?書記官.+?[ |\\r]*\\n'\n","# pattern = r'刑事第.+庭.+?書記官.+\\s*'\n","# re.findall(pattern, jud, re.DOTALL)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"n4gbsCVbXUTT"},"source":["# ChatGLM2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84NSRRX4XUTT"},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModel, AutoConfig\n","tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm2-6b\", trust_remote_code=True)\n","config = AutoConfig.from_pretrained(\"THUDM/chatglm2-6b-int4\", trust_remote_code=True, output_hidden_states=True, output_attentions = True)\n","\n","# model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b\", config=config, trust_remote_code=True).half().cuda()\n","# model = model.eval()\n","model = AutoModel.from_pretrained(\"THUDM/chatglm2-6b-int4\", config=config, trust_remote_code=True).cuda()\n","\n","response, history = model.chat(tokenizer, \"你好\", history=[])\n","print(response)"]},{"cell_type":"markdown","metadata":{"id":"ZMAK9mlqLDMK"},"source":["# Check 地院資料"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":66186,"status":"ok","timestamp":1705250594516,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"s4VGORcyLORO","outputId":"c422e5ac-c286-43e2-b70a-957a49adfe25"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","dir_path = '/gdrive/MyDrive/資料庫'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":94600,"status":"ok","timestamp":1705250806981,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"-oP3aU_6LHaH","outputId":"6632e751-5a04-4cdb-86db-0a80190eb6a7"},"outputs":[],"source":["import pandas as pd\n","basic_df = pd.read_csv('/gdrive/MyDrive/資料庫/111地院判決書_無簡_全文_移除符號.csv')\n","opinion_df = pd.read_csv('/gdrive/MyDrive/資料庫/1222_opinion_sentence_district_embedding.csv')\n","print(\"111地院判決書_無簡_全文_移除符號.csv: \", len(basic_df))\n","print(\"1222_opinion_sentence_district_embedding.csv: \", len(opinion_df))\n","# c_ori = pd.read_csv('/cluster/home/lawrencechh.cs/cdf_dataset/20231204_dic_-001.csv')\n","\n","# print(\"output.csv: \", len(b_ori))\n","# print(\"20231204_dic_-001.csv\", len(c_ori))\n","# tmp_df = b_ori[b_ori['JID'].isin(c_ori['case_num'])]\n","# # tmp_df = c_ori[c_ori['case_num'].isin(b_ori['JID'])]\n","# print(\"Same Jud: \", len(tmp_df))\n","# print(list(b_ori.columns))\n","# print(list(c_ori.columns))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705250957799,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"stVB26GC4F5Y","outputId":"4f37422a-c2bb-4fa7-9d3b-c9d5ffea3997"},"outputs":[],"source":["print('basic_df:', basic_df.columns)\n","print('opinion_df:', opinion_df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1705250993021,"user":{"displayName":"LawrenceCH H","userId":"08439437395459958705"},"user_tz":-480},"id":"jQz60M_gLsie","outputId":"5cdbe9e1-0ffc-4acb-c20b-2bf895eecfb4"},"outputs":[],"source":["print(len(basic_df[basic_df['tar_JID'].isin(opinion_df['JID'])]))\n"]},{"cell_type":"markdown","metadata":{},"source":["# 20240119 Store_embedding"]},{"cell_type":"markdown","metadata":{},"source":["# 20240119 Merge basic_csv and categories"]},{"cell_type":"markdown","metadata":{},"source":["## Load seperate csv files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","# court_type_df = pd.read_csv('/workspace/111資料/111判決書院別/111判決書院別.csv')\n","# jud_date_df = pd.read_csv('/workspace/111資料/111判決書日期/111_date.csv')\n","# # case_kind and basic_info are in same paragraph\n","# basic_info_df = pd.read_csv('/workspace/111資料/111判決書案由與基本資料/data.csv')\n","# syllabus_df = pd.read_csv('/workspace/111資料/111判決書主文及去符號全文/111_main.csv')\n","# jud_full_df = pd.read_csv('/workspace/111資料/111判決書全文_含上級審與地院_有符號與無符號/18個檔案的地院111判決書_無簡_全文_未移除符號.csv')\n","\n","# fee_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_ft_paragraph_district_TARGET.csv')\n","# opinion_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_op_sentence_district_TARGET.csv')\n","# sub_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_sub_paragraph_district_TARGET.csv')\n","\n","print('court_type_df length:', len(court_type_df))\n","print('court_type_df columns:', court_type_df.columns)\n","print('jud_date_df length:', len(jud_date_df))\n","print('jud_date_df columns:', jud_date_df.columns)\n","print('basic_info_df length:', len(basic_info_df))\n","print('basic_info_df columns:', basic_info_df.columns)\n","print('syllabus_df length:', len(syllabus_df))\n","print('syllabus_df columns:', syllabus_df.columns)\n","print('jud_full_df length:', len(jud_full_df))\n","print('jud_full_df columns:', jud_full_df.columns)\n","\n","print('fee_df columns:', len(fee_df), '\\nfee_df last data index', fee_df.iloc[-1].name)\n","print('opinion_df length:', len(opinion_df), '\\nopinion_df last data index', opinion_df.iloc[-1].name)\n","print('sub_df length:', len(sub_df), '\\nsub_df last data index', sub_df.iloc[-1].name)\n","\n","df_list = [[court_type_df, 'court_type_df'], [basic_info_df, 'basic_info_df'], [syllabus_df,'syllabus_df'], [jud_full_df, 'jud_full_df']] \n","for tmp_list in df_list:\n","    print(f'jud_date_df JID == {tmp_list[1]} JID:', tmp_list[0]['JID'].tolist()==jud_date_df['JID'].tolist())\n","\n","print('Same JID between syllabus_df and jud_date_df:', len(syllabus_df[syllabus_df['JID'].isin(jud_date_df['JID'])]))\n","print('Same JID between syllabus_df and fee_df:', len(syllabus_df[syllabus_df['JID'].isin(fee_df['JID'])]))\n","print('Same JID between syllabus_df and opinion_df:', len(syllabus_df[syllabus_df['JID'].isin(opinion_df['JID'])]))\n","print('Same JID between syllabus_df and sub_df:', len(syllabus_df[syllabus_df['JID'].isin(sub_df['JID'])]))\n","\n","not_in_basic_info = jud_full_df[~jud_full_df['JID'].isin(basic_info_df['JID'])]\n","print('Numbers of JID not in basic_info_df: ', len(not_in_basic_info))\n","# # Check if JID is unique\n","# list(set(fee_df['JID'].tolist()))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Merge several target columns to main_basic.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["jud_date_merged = jud_date_df.copy()\n","jud_date_merged = jud_date_merged.merge(basic_info_df[['JID', 'Pair']], on='JID', how='left')\n","# # Check jud_date_merged['Pair] are correctly merged\n","# print('jud_date_merged length: ', len(jud_date_merged))\n","# import random\n","# inbasic = jud_date_merged[jud_date_merged['JID'].isin(basic_info_df['JID'])]\n","# print('inbasic length: ', len(inbasic))\n","# for i in range(20):\n","#     print(inbasic.iloc[random.choice(range(len(inbasic)))])\n","basic_info_list = jud_date_merged['Pair'].tolist()\n","\n","main_basic_df = pd.DataFrame({\n","                              'UID': [data_index for data_index in range(len(jud_date_df))],\n","                              'JID': jud_date_df['JID'].tolist(),\n","                              'court_type': court_type_df['court'].tolist(),\n","                              'jud_date': jud_date_df['date'].tolist(),\n","                              'basic_info': basic_info_list,\n","                              'syllabus': syllabus_df['main'].tolist(),\n","                              'jud_full': jud_full_df['JFULL'].tolist(),\n","                              'jud_url': [f'https://judgment.judicial.gov.tw/FJUD/data.aspx?ty=JD&id={jid}' for jid in jud_date_df['JID']],\n","                              })\n","print('main_basic_df length: ', len(main_basic_df))\n","\n","# # Check main_basic_df is correctly stored\n","for i in range(20):\n","    # print(main_basic_df.iloc[random.choice(range(len(main_basic_df)))])\n","    random_data = main_basic_df.iloc[random.choice(range(len(main_basic_df)))]\n","    print(random_data)\n","    # print(random_data['JID'])\n","    # print(random_data['jud_url'])\n","# # Save DataFrame to csv\n","# main_basic_df.to_csv('/workspace/111資料/20240120_main_basic.csv', encoding='utf-8-sig', index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Add UID to category_csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","# main_basic_df = pd.read_csv('/workspace/111資料/20240120_main_basic.csv')\n","df_list = [fee_df, opinion_df, sub_df]\n","file_name = ['fee', 'opinion', 'sub']\n","for tmp_index, tmp_df in enumerate(df_list):\n","    \n","    tmp_merged = tmp_df.copy()\n","    tmp_merged = tmp_merged.merge(main_basic_df[['JID', 'UID']], on='JID', how='left')\n","    tmp_merged = tmp_merged.rename(columns={'Unnamed: 0':'EID'})\n","    print('tmp_merged length:', len(tmp_merged))\n","    print('Number of unique JID:', len(list(set(tmp_merged['JID'].tolist()))))\n","    print(\"Number of tmp_merged['UID'] is nan: \", len(tmp_merged[tmp_merged['UID'].isna()]))\n","    print()\n","    tmp_merged.to_csv(f'/workspace/111資料/20240120_category_{file_name[tmp_index]}.csv', encoding='utf-8-sig', index=False)\n","    # # # Check tmp_merged is correctly merged\n","    # for i in range(20):\n","    #     random_data = tmp_merged.iloc[random.choice(range(len(tmp_merged)))]\n","    #     print(random_data)\n","    #     # main_basic_df_tmp = main_basic_df[main_basic_df['JID']==random_data['JID']]\n","    #     # print('main_basic_df_tmp: ', main_basic_df_tmp.iloc[0]['JID'], main_basic_df_tmp.iloc[0]['UID'])\n","    #     # print('random_data', random_data['JID'], random_data['UID'])\n","    #     # print(main_basic_df_tmp.iloc[0]['JID']==random_data['JID'])\n","    #     # print(main_basic_df_tmp.iloc[0]['UID']==random_data['UID'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check Saved csv\n","file_name = ['fee', 'opinion', 'sub']\n","for name in file_name:\n","    tmp_df = pd.read_csv(f'/workspace/111資料/20240120_category_{name}.csv')\n","    print(f'File: {name}, Length: {len(tmp_df)}')\n","    print('Unique JID length:', len(list(set(tmp_df['JID'].tolist()))))\n","    print('Unique UID length:', len(list(set(tmp_df['UID'].tolist()))))\n","    print('Unique EID length:', len(list(set(tmp_df['EID'].tolist()))))\n","    print('Last Data:\\n')\n","    print(tmp_df.iloc[-1])\n","    print()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","# jud_date_df = pd.read_csv('/workspace/111資料/111判決書日期/111_date.csv')\n","# syllabus_df = pd.read_csv('/workspace/111資料/111判決書主文及去符號全文/111_main.csv')\n","# jud_full_df = pd.read_csv('/workspace/111資料/111判決書全文_含上級審與地院_有符號與無符號/18個檔案的地院111判決書_無簡_全文_未移除符號.csv')\n","# fee_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_ft_paragraph_district_TARGET.csv')\n","# opinion_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_op_sentence_district_TARGET.csv')\n","# sub_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_sub_paragraph_district_TARGET.csv')\n","print('syllabus_df length:', len(syllabus_df))\n","print('jud_date_df length:', len(jud_date_df))\n","print('jud_full_df length:', len(jud_full_df))\n","print('fee_df length:', len(fee_df), '\\nfee_df last data index', fee_df.iloc[-1].name)\n","print('opinion_df length:', len(opinion_df), '\\nopinion_df last data index', opinion_df.iloc[-1].name)\n","print('sub_df length:', len(sub_df), '\\nsub_df last data index', sub_df.iloc[-1].name)\n","\n","print('Same JID between syllabus_df and jud_date_df:', len(syllabus_df[syllabus_df['JID'].isin(jud_date_df['JID'])]))\n","print('Same JID between syllabus_df and fee_df:', len(syllabus_df[syllabus_df['JID'].isin(fee_df['JID'])]))\n","print('Same JID between syllabus_df and opinion_df:', len(syllabus_df[syllabus_df['JID'].isin(opinion_df['JID'])]))\n","print('Same JID between syllabus_df and sub_df:', len(syllabus_df[syllabus_df['JID'].isin(sub_df['JID'])]))\n","\n","# # Check if JID is unique\n","# list(set(fee_df['JID'].tolist()))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["target_df_paths = [[r'/workspace/111資料/111判決書提出標註目標/0114_op_sentence_district_TARGET.csv', 0],\n","                   [r'/workspace/111資料/111判決書提出標註目標/0114_ft_paragraph_district_TARGET.csv', 0],\n","                   [r'/workspace/111資料/111判決書提出標註目標/0114_sub_paragraph_district_TARGET.csv', 0]]\n","len(target_df_paths)\n","target_df_paths[0][0]\n","# target_df_paths[0][1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# Store in vector database\n","import numpy as np\n","# import faiss\n","from tqdm import tqdm\n","dir_path = '/cluster/home/lawrencechh.cs/cdf_dataset/'\n","\n","checkpoint_paths = [r'/workspace/111資料/20230620_724td_opinion_-6b-pt-token-1024-3e-3_0818/checkpoint-1200', \n","                    r'/workspace/111資料/20230819_1070td_ft_-6b-pt-token-1024-3e-3_0818_2/checkpoint-1200', \n","                    r'/workspace/111資料/if_sub_train_09262209_-6b-pt-token1024-2e-2/checkpoint-1500']\n","\n","target_df_paths = [[r'/workspace/111資料/111判決書提出標註目標/0114_op_sentence_district_TARGET.csv', 50102],\n","                   [r'/workspace/111資料/111判決書提出標註目標/0114_ft_paragraph_district_TARGET.csv', 0],\n","                   [r'/workspace/111資料/111判決書提出標註目標/0114_sub_paragraph_district_TARGET.csv', 0]]\n","\n","llm_path = r'/workspace/LLM/chatglm2-6b'\n","for df_index in range(len(target_df_paths)):\n","    merged_model = load_glm_checkpoint(checkpoint_paths[df_index], llm_path)\n","    tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\n","\n","    path = target_df_paths[df_index][0]\n","    embedding_df_length = target_df_paths[df_index][1]\n","\n","    output_csv_path = path.split('.csv')\n","    output_csv_path = output_csv_path[0] + '_embedding.csv'\n","    print(output_csv_path)\n","    df = pd.read_csv(path, encoding='utf-8-sig')[embedding_df_length:]\n","    \n","    \n","    # basic_column, category_column, target_column_name = df.columns[0], df.columns[1], df.columns[2]\n","    output_df = pd.DataFrame(columns=list(df.columns)+['embedding'])\n","\n","    if os.path.isfile(output_csv_path) == False:\n","        output_df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n","    else:\n","        print(\"File exists, append data to existed file.\")\n","\n","    stop_num = 0\n","    for i in tqdm(range(len(df))):\n","        tmp_data_dict = dict(df.iloc[i])\n","        input_text = tmp_data_dict['sentence']\n","        embedding = get_mean_pooling_embedding(input_text, tokenizer, merged_model)\n","        embedding = str(embedding.to(\"cpu\").numpy().astype(np.float32).tolist())        \n","        tmp_data_dict['embedding'] = embedding\n","        \n","        output_df.loc[0] = tmp_data_dict\n","        output_df.to_csv(output_csv_path, mode=\"a\", index=False, header=False, encoding='utf-8-sig')\n","\n","        gc.collect()\n","        embedding = None\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        \n","\n","    "]},{"cell_type":"markdown","metadata":{},"source":["# 20240223 Remove data of (最高法院、高院) from fee and sub"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import faiss\n","\n","main_basic_df = pd.read_csv('/workspace/111資料/db_loaded/20240120_main_basic.csv')\n","opinion_df = pd.read_csv('/workspace/111資料/db_loaded/20240120_category_opinion.csv')\n","sub_df = pd.read_csv('/workspace/111資料/db_loaded/20240120 含高院、最高法院/20240120_category_sub.csv')\n","fee_df = pd.read_csv('/workspace/111資料/db_loaded/20240120 含高院、最高法院/20240120_category_fee.csv')\n","\n","opinion_flat = faiss.read_index('/workspace/111資料/db_loaded/0114_op_sentence_district_TARGET_embedding.bin')\n","fee_flat = faiss.read_index('/workspace/111資料/db_loaded/20240120 含高院、最高法院/0114_ft_paragraph_district_TARGET_embedding.bin')\n","sub_flat = faiss.read_index('/workspace/111資料/db_loaded/20240120 含高院、最高法院/0114_sub_paragraph_district_TARGET_embedding.bin')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def remove_indices_from_df_and_flat(basic_df, category_df, index_flat, category_name):\n","\n","    # Merge category_df and basic_df\n","    target_basic_df_columns = basic_df.columns.tolist()\n","    del target_basic_df_columns[target_basic_df_columns.index('JID')]\n","    merged_df = category_df.merge(basic_df[target_basic_df_columns], on='UID', how='left')\n","    # merged_df.rename(columns={'sentence': category_name}, inplace=True)\n","\n","    # Remove rows according to index\n","    # removed_indices = merged_df[merged_df['court_type'].isin(['最高法院', '高等法院'])].index\n","    removed_indices = merged_df[merged_df['court_type'].str.contains('高等法院') | merged_df['court_type'].str.contains('最高法院')].index\n","    merged_df.drop(removed_indices, inplace=True)\n","    merged_df.reset_index(inplace=True, drop=True)\n","    merged_df['EID'] = merged_df.index\n","\n","    print('merged_df length:', len(merged_df))\n","\n","    # Remove vectors according to index\n","    index_flat.remove_ids(removed_indices)\n","    print(f'{category_name}_flat length:', index_flat.ntotal)\n","\n","    # Keep only certain columns ['EID', 'JID', 'sentence', 'type', 'UID']\n","    merged_df = merged_df[['EID', 'JID', 'sentence', 'type', 'UID']]\n","    \n","    # # Save\n","    # merged_df.to_csv(f'/workspace/111資料/db_loaded/20240225_category_{category_name}.csv', encoding='utf-8-sig', index=False)\n","    # faiss.write_index(index_flat, f\"/workspace/111資料/db_loaded/20240225_embedding_{category_name}.bin\")\n","\n","remove_indices_from_df_and_flat(main_basic_df, sub_df, sub_flat, 'sub')\n","remove_indices_from_df_and_flat(main_basic_df, fee_df, fee_flat, 'fee')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["nc_flat = faiss.read_index('/workspace/111資料/db_loaded/20240225_embedding_sub.bin')\n","nc_df = pd.read_csv('/workspace/111資料/db_loaded/20240225_category_sub.csv')\n","\n","# print(set(nc_df['court_type']))\n","# print(fee_flat.ntotal)\n","# print(nc_flat.ntotal)\n","\n","# print(fee_flat.reconstruct(108))\n","# print(nc_flat.reconstruct(0))\n","# print(fee_df.iloc[108])\n","print(nc_df.iloc[0])"]},{"cell_type":"markdown","metadata":{},"source":["# 20240119 Merge basic_csv and categories"]},{"cell_type":"markdown","metadata":{},"source":["## Load seperate csv files"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import os\n","\n","# court_type_df = pd.read_csv('/workspace/111資料/111判決書院別/111判決書院別.csv')\n","# jud_date_df = pd.read_csv('/workspace/111資料/111判決書日期/111_date.csv')\n","# # case_kind and basic_info are in same paragraph\n","# basic_info_df = pd.read_csv('/workspace/111資料/111判決書案由與基本資料/data.csv')\n","# syllabus_df = pd.read_csv('/workspace/111資料/111判決書主文及去符號全文/111_main.csv')\n","# jud_full_df = pd.read_csv('/workspace/111資料/111判決書全文_含上級審與地院_有符號與無符號/18個檔案的地院111判決書_無簡_全文_未移除符號.csv')\n","\n","# fee_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_ft_paragraph_district_TARGET.csv')\n","# opinion_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_op_sentence_district_TARGET.csv')\n","# sub_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_sub_paragraph_district_TARGET.csv')\n","\n","print('court_type_df length:', len(court_type_df))\n","print('court_type_df columns:', court_type_df.columns)\n","print('jud_date_df length:', len(jud_date_df))\n","print('jud_date_df columns:', jud_date_df.columns)\n","print('basic_info_df length:', len(basic_info_df))\n","print('basic_info_df columns:', basic_info_df.columns)\n","print('syllabus_df length:', len(syllabus_df))\n","print('syllabus_df columns:', syllabus_df.columns)\n","print('jud_full_df length:', len(jud_full_df))\n","print('jud_full_df columns:', jud_full_df.columns)\n","\n","print('fee_df columns:', len(fee_df), '\\nfee_df last data index', fee_df.iloc[-1].name)\n","print('opinion_df length:', len(opinion_df), '\\nopinion_df last data index', opinion_df.iloc[-1].name)\n","print('sub_df length:', len(sub_df), '\\nsub_df last data index', sub_df.iloc[-1].name)\n","\n","df_list = [[court_type_df, 'court_type_df'], [basic_info_df, 'basic_info_df'], [syllabus_df,'syllabus_df'], [jud_full_df, 'jud_full_df']] \n","for tmp_list in df_list:\n","    print(f'jud_date_df JID == {tmp_list[1]} JID:', tmp_list[0]['JID'].tolist()==jud_date_df['JID'].tolist())\n","\n","print('Same JID between syllabus_df and jud_date_df:', len(syllabus_df[syllabus_df['JID'].isin(jud_date_df['JID'])]))\n","print('Same JID between syllabus_df and fee_df:', len(syllabus_df[syllabus_df['JID'].isin(fee_df['JID'])]))\n","print('Same JID between syllabus_df and opinion_df:', len(syllabus_df[syllabus_df['JID'].isin(opinion_df['JID'])]))\n","print('Same JID between syllabus_df and sub_df:', len(syllabus_df[syllabus_df['JID'].isin(sub_df['JID'])]))\n","\n","not_in_basic_info = jud_full_df[~jud_full_df['JID'].isin(basic_info_df['JID'])]\n","print('Numbers of JID not in basic_info_df: ', len(not_in_basic_info))\n","# # Check if JID is unique\n","# list(set(fee_df['JID'].tolist()))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Merge several target columns to main_basic.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["jud_date_merged = jud_date_df.copy()\n","jud_date_merged = jud_date_merged.merge(basic_info_df[['JID', 'Pair']], on='JID', how='left')\n","# # Check jud_date_merged['Pair] are correctly merged\n","# print('jud_date_merged length: ', len(jud_date_merged))\n","# import random\n","# inbasic = jud_date_merged[jud_date_merged['JID'].isin(basic_info_df['JID'])]\n","# print('inbasic length: ', len(inbasic))\n","# for i in range(20):\n","#     print(inbasic.iloc[random.choice(range(len(inbasic)))])\n","basic_info_list = jud_date_merged['Pair'].tolist()\n","\n","main_basic_df = pd.DataFrame({\n","                              'UID': [data_index for data_index in range(len(jud_date_df))],\n","                              'JID': jud_date_df['JID'].tolist(),\n","                              'court_type': court_type_df['court'].tolist(),\n","                              'jud_date': jud_date_df['date'].tolist(),\n","                              'basic_info': basic_info_list,\n","                              'syllabus': syllabus_df['main'].tolist(),\n","                              'jud_full': jud_full_df['JFULL'].tolist(),\n","                              'jud_url': [f'https://judgment.judicial.gov.tw/FJUD/data.aspx?ty=JD&id={jid}' for jid in jud_date_df['JID']],\n","                              })\n","print('main_basic_df length: ', len(main_basic_df))\n","\n","# # Check main_basic_df is correctly stored\n","for i in range(20):\n","    # print(main_basic_df.iloc[random.choice(range(len(main_basic_df)))])\n","    random_data = main_basic_df.iloc[random.choice(range(len(main_basic_df)))]\n","    print(random_data)\n","    # print(random_data['JID'])\n","    # print(random_data['jud_url'])\n","# # Save DataFrame to csv\n","# main_basic_df.to_csv('/workspace/111資料/20240120_main_basic.csv', encoding='utf-8-sig', index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Add UID to category_csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","# main_basic_df = pd.read_csv('/workspace/111資料/20240120_main_basic.csv')\n","df_list = [fee_df, opinion_df, sub_df]\n","file_name = ['fee', 'opinion', 'sub']\n","for tmp_index, tmp_df in enumerate(df_list):\n","    \n","    tmp_merged = tmp_df.copy()\n","    tmp_merged = tmp_merged.merge(main_basic_df[['JID', 'UID']], on='JID', how='left')\n","    tmp_merged = tmp_merged.rename(columns={'Unnamed: 0':'EID'})\n","    print('tmp_merged length:', len(tmp_merged))\n","    print('Number of unique JID:', len(list(set(tmp_merged['JID'].tolist()))))\n","    print(\"Number of tmp_merged['UID'] is nan: \", len(tmp_merged[tmp_merged['UID'].isna()]))\n","    print()\n","    tmp_merged.to_csv(f'/workspace/111資料/20240120_category_{file_name[tmp_index]}.csv', encoding='utf-8-sig', index=False)\n","    # # # Check tmp_merged is correctly merged\n","    # for i in range(20):\n","    #     random_data = tmp_merged.iloc[random.choice(range(len(tmp_merged)))]\n","    #     print(random_data)\n","    #     # main_basic_df_tmp = main_basic_df[main_basic_df['JID']==random_data['JID']]\n","    #     # print('main_basic_df_tmp: ', main_basic_df_tmp.iloc[0]['JID'], main_basic_df_tmp.iloc[0]['UID'])\n","    #     # print('random_data', random_data['JID'], random_data['UID'])\n","    #     # print(main_basic_df_tmp.iloc[0]['JID']==random_data['JID'])\n","    #     # print(main_basic_df_tmp.iloc[0]['UID']==random_data['UID'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check Saved csv\n","file_name = ['fee', 'opinion', 'sub']\n","for name in file_name:\n","    tmp_df = pd.read_csv(f'/workspace/111資料/20240120_category_{name}.csv')\n","    print(f'File: {name}, Length: {len(tmp_df)}')\n","    print('Unique JID length:', len(list(set(tmp_df['JID'].tolist()))))\n","    print('Unique UID length:', len(list(set(tmp_df['UID'].tolist()))))\n","    print('Unique EID length:', len(list(set(tmp_df['EID'].tolist()))))\n","    print('Last Data:\\n')\n","    print(tmp_df.iloc[-1])\n","    print()\n"]},{"cell_type":"markdown","metadata":{},"source":["# 20240320 RE basic info "]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from tqdm import tqdm\n","import re\n","# # main_basic_df = pd.read_csv('/workspace/111資料/db_loaded/20240120_main_basic.csv')\n","# # main_basic_df = pd.read_csv('/workspace/111資料/db_loaded/20240228_main_basic.csv')\n","# main_basic_df = pd.read_csv('/home/lawrencechh/workspace/111資料/db_loaded/20240228_main_basic.csv')\n","# print('main_basic_df length:', len(main_basic_df))\n","# # nona_df = main_basic_df[~main_basic_df['basic_info_20240120'].isna()]\n","# nona_df = main_basic_df.copy()\n","# print('nona_df length:', len(nona_df))\n","# print()\n","# print(nona_df.iloc[0])\n","# print(nona_df.iloc[0]['jud_url'])\n"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Start get_re_multi_matched_list()\n","matched_indices [[]]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 73637/73637 [00:00<00:00, 201108.48it/s]\n"]},{"name":"stdout","output_type":"stream","text":["matched: [73637]\n","empty: 0\n","[]\n","Start get_re_multi_matched_list()\n","matched_indices [[], [], [], []]\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 73637/73637 [00:00<00:00, 229417.09it/s]"]},{"name":"stdout","output_type":"stream","text":["matched: [73350, 95, 10, 161]\n","empty: 21\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# # 20240305 re jud_full\n","# Get case_num, basic_info, case_type\n","def get_re_multi_matched_list(input_text_list, rule_patterns, remove_special_signs=False):\n","    print('Start get_re_multi_matched_list()')\n","    error_signs = ['\\xa0', '\\u3000', '\\u30005', '\\u3000111', '\\u30004', '\\u300011', '\\u30003', '\\u300024', '&nbsp;', '\\u3000110', '\\u300012', '\\u300030', ' ', '\\r']\n","    matched_indices = [[] for _ in range(len(rule_patterns))]\n","    empty_list = []\n","    print('matched_indices', matched_indices)\n","    # ---------------------------\n","    if remove_special_signs:\n","        for input_list_order in range(len(input_text_list)):\n","            input_text = input_text_list[input_list_order][1]\n","            for sign in error_signs:\n","                input_text = input_text.replace(sign, '')\n","            input_text_list[input_list_order][1] = input_text\n","    # ---------------------------\n","    for input_list_order in tqdm(range(len(input_text_list))):\n","        input_text = input_text_list[input_list_order][1]\n","        df_id = input_text_list[input_list_order][0]\n","        for rule_index, pattern in enumerate(rule_patterns):\n","            search_matched = re.search(pattern, input_text, re.DOTALL)\n","            if search_matched:\n","                # search_matched_groups = search_matched.groups()\n","                # length_below_50 = True\n","                # for input_list_order in range(3):\n","                #     if len(search_matched_groups[input_list_order]) > 50:\n","                #         length_below_50 = False\n","                #         break\n","                # if length_below_50:\n","                #     matched_indices[rule_index].append([df_id, search_matched])\n","                #     break\n","                matched_indices[rule_index].append([input_list_order, df_id, search_matched.groups(), [len(group) for group in search_matched.groups()]])\n","                break\n","\n","        if not search_matched:\n","            empty_list.append([input_list_order, df_id, input_text])\n","    matched_length = [len(matched) for matched in matched_indices]\n","    print('matched:', matched_length)\n","    print('empty:', len(empty_list))\n","    return [matched_indices, empty_list]\n","\n","input_texts = [[index, row['JFULL'][:4000]] for index, row in dfs[5][1].iterrows()]\n","result_list = get_re_multi_matched_list(input_texts, [r'(.+?)主 *?文'], True)\n","print(result_list[1])\n","\n","input_texts = [[df_id, re_text[0]] for _, df_id, re_text, _ in result_list[0][0]]\n","basic_info_patterns = [\n","        r'(.+?第\\d+號)\\n(.+?)上列.+?因(.+?)[（|、|，]',\n","        r'(.+?號)\\n([上訴人|聲請人|公訴人|自訴人].+?)[上|上列|以上|下列].+?因(.+?)[（|、|，]',\n","        r'(.+?第\\d+號)\\n?(.+?)[上|上列|以上|下列].+?因(.+?)[（|、|，]',\n","        r'(.+?)\\n([上訴人|聲請人|公訴人|自訴人].+)\\n(.+?案件)',\n","]\n","result_list = get_re_multi_matched_list(input_texts, basic_info_patterns, False)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[3031, 3031, '臺灣桃園地方法院刑事判決109年度易字第670\\n號公訴人臺灣桃園地方檢察署檢察官\\n被告MARINRAYANSIMANGAN（菲律賓籍）\\n\\n\\n\\n選任辯護人謝幸伶律師（法律扶助律師）\\n上列被告因違反性騷擾防治法案件，經檢察官提起公訴（108年\\n度偵字第23052號），本院判決如下：\\n']\n","[4711, 4711, '臺灣臺南地方法院刑事判決\\n109年度簡上字第324號\\n上訴人\\n即被告陳信元\\n\\n\\n本院中華民國109年9月4日109年度簡字第2334號第一審簡易判決\\n（聲請簡易判決處刑案號：109年度偵字第10672號），提起上訴\\n，被告於本院審理進行中，就被訴事實為有罪之陳述，經本院管\\n轄之第二審合議庭裁定進行簡式審判程序，判決如下：\\n']\n","[10227, 10227, '臺灣臺中地方法院刑事判決109年度易字第2070\\n號公訴人臺灣臺中地方檢察署檢察官\\n被告林宗陞\\n\\n\\n指定辯護人本院公設辯護人賴泰鈞\\n上列被告因竊盜案件，經檢察官提起公訴（109年度偵字第00000\\n號），被告於審理程序中就被訴事實為有罪之陳述，復經檢察官\\n聲請改依協商程序，本院進行協商程序，判決如下：\\n']\n","[11362, 11362, '臺灣苗栗地方法院刑事判決109年度易字第507\\n號公訴人臺灣苗栗地方檢察署檢察官\\n被告李冠良\\n\\n\\n\\n指定辯護人本院公設辯護人蔡文亮\\n上列被告因違反毒品危害防制條例案件，經檢察官提起公訴（10\\n9年度毒偵字第580號），本院判決如下：\\n']\n","[13121, 13121, '.臺灣高雄地方法院刑事判決110年度易字第37\\n號公訴人臺灣高雄地方檢察署檢察官\\n被告劉呈澤\\n\\n\\n\\n\\n上列被告因竊盜等案件，經檢察官提起公訴（109年度偵字第00\\n000號），因被告就被訴事實均為有罪之陳述，經本院告知簡式\\n審判程序意旨，並聽取公訴人、被告之意見後，裁定依簡式審判\\n程序審理，判決如下：\\n']\n","[19601, 19601, '臺灣高等法院臺南分院刑事判決\\n110年度上訴字第293號\\n上訴人\\n即被告黃逸嫻\\n\\n\\n上列上訴人不服臺灣臺南地方法院108年度訴字第897號中華民國\\n109年11月12日第一審判決（起訴案號：臺灣臺南地方檢察署108\\n年度偵字第623號），提起上訴，本院判決如下：\\n']\n","[30091, 30091, '臺灣澎湖地方法院刑事判決110年度交易字第8號\\n公訴人臺灣澎湖地方檢察署檢察官\\n被告莊橙啟\\n\\n\\n\\n指定辯護人本院公設辯護人張寅煥\\n']\n","[30092, 30092, '臺灣澎湖地方法院刑事判決110年度交易字第9號\\n公訴人臺灣澎湖地方檢察署檢察官\\n被告謝順典\\n\\n\\n\\n指定辯護人本院公設辯護人張寅煥\\n']\n","[37097, 37097, '臺灣新北地方法院刑事判決110年度易字第486號\\n聲請人臺灣新北地方檢察署檢察官\\n被告蘇']\n","[38852, 38852, '最高法院刑事判決110年度台上字第4126號\\n上訴人陳誌賢\\n\\n\\n\\n謝坤霖\\n\\n\\n\\n黃韋文\\n\\n\\n\\n上一人\\n選任辯護人許哲嘉律師\\n']\n","[39235, 39235, '福建金門地方法院刑事判決\\n110年度附民字第11號\\n原告宋宜璠\\n被告朱平源\\n\\n上列被告經原告提起附帶民事訴訟，請求損害賠償，本院判決如\\n下︰\\n']\n","[39555, 39555, '臺灣基隆地方法院刑事判決\\n110年度簡上字第41號\\n上訴人臺灣基隆地方檢察署檢察官\\n被告張雅雯\\n\\n\\n\\n\\n上列上訴人不服本院基隆簡易庭中華民國110年3月5日110年度基\\n簡字第187號第一審簡易判決（聲請簡易判決處刑書案號：109年\\n度偵字第7060號），提起上訴，本院管轄之第二審合議庭判決如\\n下：\\n']\n","[44594, 44594, '臺灣高等法院臺南分院刑事判決\\n110年度上訴字第836號\\n上訴人\\n即被告許育銓\\n\\n上列上訴人即被告不服臺灣臺南地方法院110年度訴字第73號中\\n華民國110年3月31日第一審判決（起訴案號：臺灣臺南地方檢察\\n署110年度偵字第1433號），提起上訴，本院判決如下：\\n']\n","[51406, 51406, '臺灣高雄地方法院刑事判決110年度交簡上字第109\\n號上訴人\\n即被告高有德\\n\\n\\n\\n\\n上列上訴人因過失傷害案件，不服本院高雄簡易庭中華民國110\\n年4月13日110年度交簡字第943號第一審簡易判決（起訴案號：\\n109年度偵緝字第1247號）提起上訴，本院判決如下：\\n']\n","[54432, 54432, '6臺灣桃園地方法院刑事判決110年度審易字第504\\n號公訴人臺灣桃園地方檢察署檢察官\\n被告鍾維龍\\n\\n\\n\\n\\n上列被告因竊盜案件，經檢察官提起公訴（110年度偵字第6856\\n號、第7162號、第7605號、第7803號），被告於本院準備程序進\\n行中，就被訴事實為有罪之陳述，經本院告知簡式審判程序意旨\\n，並聽取當事人之意見後，裁定依簡式審判程序審理，判決如下\\n：\\n']\n","[61621, 61621, '臺灣桃園地方法院刑事判決110年度訴字第312號\\n公訴人臺灣桃園地方檢察署檢察官\\n被告潘宏偉\\n\\n\\n指定辯護人鐘烱錺律師\\n']\n","[65039, 65039, '臺灣高等法院臺南分院刑事判決\\n110年度上易字第568號\\n上訴人\\n即被告黃志如\\n\\n上列上訴人即被告不服臺灣臺南地方法院110年度易字第549號中\\n華民國110年7月28日第一審判決（起訴案號：臺灣臺南地方檢察\\n署110年度偵字第3579號），提起上訴，本院判決如下：\\n']\n","[65042, 65042, '臺灣高等法院臺南分院刑事判決\\n110年度上易字第601號\\n上訴人\\n即被告詹健源\\n\\n\\n\\n\\n上列上訴人不服臺灣雲林地方法院110年度易字第129號中華民國\\n110年10月8日第一審判決（起訴案號：臺灣雲林地方檢察署110\\n年度偵字第176號），提起上訴，本院判決如下：\\n']\n","[65813, 65813, '臺灣高雄地方法院刑事判決110年度除字第274號\\n聲請人洪春菊\\n上列當事人聲請宣告證券無效事件，本院於民國110年10月26日\\n言詞辯論終結，判決如下：\\n']\n","[68143, 68143, '臺灣新北地方法院刑事判決\\n110年度審易字第2028號\\n公訴人臺灣新北地方檢察署檢察官\\n被告楊立暐\\n\\n\\n\\n']\n","[68386, 68386, '臺灣新北地方法院刑事判決\\n110年度訴字第357號\\n公訴人臺灣新北地方檢察署檢察官\\n被告陳定宏\\n\\n\\n\\n指定辯護人本院公設辯護人姚孟岑\\n']\n","matched_list length:  0\n","empty_list length:  21\n"]}],"source":["# Check empty list\n","count = 0\n","matched_list = []\n","empty_list = []\n","for text in result_list[1]:\n","    \n","    # input_text = text[1].replace('\\n', '')\n","    input_text = text[2]\n","\n","    # matched = re.search(r'(.+?)\\n([上訴人|聲請人|公訴人|自訴人].+?)[上|上列|以上|下列].+?因(.+?)[（|、|，]', input_text, re.DOTALL)\n","    matched = re.search(r'(.+?)\\n([上訴人|聲請人|公訴人|自訴人].+)\\n(.+?案件)', input_text, re.DOTALL)\n","    \n","    if matched:\n","        matched_list.append(matched)\n","        # print(text)\n","\n","        print(matched.groups())\n","    else:\n","        print(text)\n","        empty_list.append(text)\n","    count+=1\n","    if count>50:\n","        break\n","\n","# print(matched_list)\n","print('matched_list length: ', len(matched_list))\n","# print(empty_list)\n","print('empty_list length: ', len(empty_list))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["rule_index:0, group_index:0, 189\n","rule_index:0, group_index:1, 36\n","rule_index:0, group_index:2, 23\n","rule_index:1, group_index:0, 67\n","rule_index:1, group_index:1, 660\n","rule_index:1, group_index:2, 1230\n","rule_index:2, group_index:0, 26\n","rule_index:2, group_index:1, 302\n","rule_index:2, group_index:2, 15\n","rule_index:3, group_index:0, 25\n","rule_index:3, group_index:1, 1\n","rule_index:3, group_index:2, 11\n","rule_index:4, group_index:0, 27\n","rule_index:4, group_index:1, 34\n","rule_index:4, group_index:2, 6\n"]}],"source":["# Show result according to rule_index and group_index\n","rule_index = 0\n","group_index = 1\n","group_length = 3\n","rule_length = len(result_list[0])\n","\n","sorted_result = []\n","for rule_index in range(rule_length):\n","    sorted_result.append([])\n","    for group_index in range(group_length):\n","        sorted_result[rule_index].append([])\n","        sorted_result[rule_index][group_index] = sorted(result_list[0][rule_index], key=lambda x: x[3][group_index], reverse=True)\n","        try:\n","            print(f'rule_index:{rule_index}, group_index:{group_index}, {sorted_result[rule_index][group_index][0][3][group_index]}')\n","            print(f'Data 0: {sorted_result[rule_index][group_index][0]}')\n","        except:\n","            continue"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Show input_text according to index\n","input_text_index = 23575\n","print([input_texts[input_text_index]])"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["rule_list: 73350\n","rule_list: 95\n","rule_list: 10\n","rule_list: 161\n"]}],"source":["# Store new csv according to original csv copy\n","# output_basic_df = main_basic_df.copy()\n","output_basic_df = dfs[5][1].copy()\n","for rule_list in result_list[0]:\n","    print('rule_list:', len(rule_list))\n","    for data in rule_list:\n","        df_index = data[1]\n","        case_num = data[2][0]\n","        basic_info = re.sub(r'\\n+', '\\n', data[2][1])\n","        case_type = data[2][2]\n","        new_data_dict = {'case_num': case_num, 'basic_info': basic_info, 'case_type': case_type}\n","\n","        for key, value in new_data_dict.items():\n","            output_basic_df.loc[df_index, key] = value\n","# output_basic_df.to_csv('/workspace/111資料/db_loaded/20240306_main_basic.csv', encoding='utf-8-sig', index=False)\n","# output_basic_df.to_csv('/workspace/data/CDB_20240304_110juds/20240320_final_merged/20240320_basic_info_110.csv', encoding='utf-8-sig', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# output_basic_df.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1, inplace=True)\n","output_basic_df.iloc[-1]\n","output_basic_df.to_csv('/home/lawrencechh/workspace/111資料/db_loaded/20240306_main_basic.csv', encoding='utf-8-sig', index=False)\n"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["73637\n","Unnamed: 0                                                44294\n","JID                                 TCHM,110,上訴,1368,20210824,1\n","JFULL         臺灣高等法院臺中分院刑事判決\\r\\n110年度上訴字第1368號\\r\\n上  訴  人  臺...\n","case_num                         臺灣高等法院臺中分院刑事判決\\n110年度上訴字第1368號\n","basic_info                             上訴人臺灣苗栗地方檢察署檢察官\\n被告周慈賢\\n\n","case_type                                                被告傷害案件\n","Name: 44294, dtype: object\n","----------------------\n","Unnamed: 0                                                10858\n","JID                                   TPDM,109,訴,920,20210219,2\n","JFULL         臺灣臺北地方法院刑事判決\\r\\n109年度訴字第920號\\r\\n公  訴  人  臺灣臺北地...\n","case_num                             臺灣臺北地方法院刑事判決\\n109年度訴字第920號\n","basic_info    公訴人臺灣臺北地方檢察署檢察官\\n被告黃昱銨\\n選任辯護人黃國鐘律師\\n被告廖嘉姿\\n選任辯...\n","case_type                                         違反毒品危害防制條例等案件\n","Name: 10858, dtype: object\n","----------------------\n","Unnamed: 0                                                57338\n","JID                                  TCHM,110,上易,798,20211012,1\n","JFULL         臺灣高等法院臺中分院刑事判決\\r\\n110年度上易字第798號\\r\\n上  訴  人  \\r...\n","case_num                          臺灣高等法院臺中分院刑事判決\\n110年度上易字第798號\n","basic_info               上訴人\\n即被告廖嘉杰（原名：羅嘉豪）\\n指定辯護人本院公設辯護人陳秋靜\\n\n","case_type                                                  竊盜案件\n","Name: 57338, dtype: object\n","----------------------\n","Unnamed: 0                                                45865\n","JID                                   CYDM,110,易,366,20210922,1\n","JFULL         臺灣嘉義地方法院刑事判決\\r\\n110年度易字第366號\\r\\n公  訴  人  臺灣嘉義地...\n","case_num                             臺灣嘉義地方法院刑事判決\\n110年度易字第366號\n","basic_info                             公訴人臺灣嘉義地方檢察署檢察官\\n被告劉得鑫\\n\n","case_type                                                  竊盜案件\n","Name: 45865, dtype: object\n","----------------------\n","Unnamed: 0                                                67213\n","JID                                   ILDM,110,原訴,29,20211216,1\n","JFULL         臺灣宜蘭地方法院刑事判決\\r\\n110年度原訴字第29號\\r\\n公  訴  人  臺灣宜蘭地...\n","case_num                             臺灣宜蘭地方法院刑事判決\\n110年度原訴字第29號\n","basic_info    公訴人臺灣宜蘭地方檢察署檢察官\\n被告陳啓明\\n義務辯護人柯林宏律師\\n被告林聖恩\\n義務辯...\n","case_type                                            毒品危害防制條例案件\n","Name: 67213, dtype: object\n","----------------------\n","Unnamed: 0                                                28697\n","JID                                   CHDM,110,訴,145,20210519,1\n","JFULL         臺灣彰化地方法院刑事判決\\r\\n110年度訴字第145號\\r\\n公  訴  人  臺灣彰化地...\n","case_num                             臺灣彰化地方法院刑事判決\\n110年度訴字第145號\n","basic_info         公訴人臺灣彰化地方檢察署檢察官\\n被告廖榮作\\n選任辯護人林尚瑜律師（法律扶助律師）\\n\n","case_type                                               加重詐欺等案件\n","Name: 28697, dtype: object\n","----------------------\n","Unnamed: 0                                                 9851\n","JID                                   CTDM,109,交訴,43,20210223,1\n","JFULL         臺灣橋頭地方法院刑事判決　　　　　　 109年度交訴字第43號\\r\\n公　訴　人　臺灣橋頭地...\n","case_num                               臺灣橋頭地方法院刑事判決109年度交訴字第43號\n","basic_info                             公訴人臺灣橋頭地方檢察署檢察官\\n被告洪雪櫻\\n\n","case_type                                                公共危險案件\n","Name: 9851, dtype: object\n","----------------------\n","Unnamed: 0                                                 6465\n","JID                                  HLHM,109,上訴,156,20210114,1\n","JFULL         臺灣高等法院花蓮分院刑事判決　　　　109年度上訴字第156號\\r\\n上　訴　人　臺灣花蓮地...\n","case_num                            臺灣高等法院花蓮分院刑事判決109年度上訴字第156號\n","basic_info                             上訴人臺灣花蓮地方檢察署檢察官\\n被告周國華\\n\n","case_type                                        被告違反毒品危害防制條例案件\n","Name: 6465, dtype: object\n","----------------------\n","Unnamed: 0                                                42873\n","JID                                   TNDM,110,易,561,20210823,1\n","JFULL         臺灣臺南地方法院刑事判決\\r\\n110年度易字第561號\\r\\n公  訴  人  臺灣臺南地...\n","case_num                             臺灣臺南地方法院刑事判決\\n110年度易字第561號\n","basic_info                             公訴人臺灣臺南地方檢察署檢察官\\n被告張春月\\n\n","case_type                                                  毀損案件\n","Name: 42873, dtype: object\n","----------------------\n","Unnamed: 0                                                17980\n","JID                                   TNDM,110,簡,554,20210326,1\n","JFULL         臺灣臺南地方法院刑事判決\\r\\n110年度簡字第554號\\r\\n公  訴  人  臺灣臺南地...\n","case_num                             臺灣臺南地方法院刑事判決\\n110年度簡字第554號\n","basic_info    公訴人臺灣臺南地方檢察署檢察官\\n被告馮欣元\\n顏宏益\\n王信凱\\n劉維柏\\n柯俊廷\\n張凱評\\n\n","case_type                                                妨害秩序案件\n","Name: 17980, dtype: object\n","----------------------\n"]}],"source":["# Check output data\n","main_basic_df = pd.read_csv('/workspace/data/CDB_20240304_110juds/20240320_final_merged/20240320_basic_info_110.csv')\n","# main_basic_df = pd.read_csv('/home/lawrencechh/workspace/111資料/db_loaded/20240228_main_basic.csv')\n","import random\n","print(len(main_basic_df))\n","for i in range(10):\n","    print(main_basic_df.iloc[random.choice(range(len(main_basic_df)))])\n","    print('----------------------')"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"data":{"text/plain":["21"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# Replace nan with 're error'\n","\n","nadf = main_basic_df.copy()\n","# nadf = main_basic_df[main_basic_df['case_num'].isna()]\n","# print(len(nadf))\n","# nadf[['case_num', 'basic_info', 'case_type']] = nadf[['case_num', 'basic_info', 'case_type']].fillna('re error')\n","# nadf.to_csv('/workspace/data/CDB_20240304_110juds/20240320_final_merged/20240320_basic_info_110.csv', encoding='utf-8-sig', index=False)\n","\n","len(main_basic_df[main_basic_df['case_num']=='re error'])\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# 20240229 CDB data numbers"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import faiss\n","main_basic_df = pd.read_csv('/workspace/111資料/db_loaded/20240228_main_basic.csv')\n","opinion_df = pd.read_csv('/workspace/111資料/db_loaded/20240120_category_opinion.csv')\n","sub_df = pd.read_csv('/workspace/111資料/db_loaded/20240225_category_sub.csv')\n","fee_df = pd.read_csv('/workspace/111資料/db_loaded/20240225_category_fee.csv')\n","old_fee_df = pd.read_csv('/workspace/111資料/db_loaded/20240120 含高院、最高法院/20240120_category_fee.csv')\n","old_sub_df = pd.read_csv('/workspace/111資料/db_loaded/20240120 含高院、最高法院/20240120_category_sub.csv')\n","\n","opinion_flat = faiss.read_index('/workspace/111資料/db_loaded/0114_op_sentence_district_TARGET_embedding.bin')\n","fee_flat = faiss.read_index('/workspace/111資料/db_loaded/20240225_embedding_fee.bin')\n","sub_flat = faiss.read_index('/workspace/111資料/db_loaded/20240225_embedding_sub.bin')"]},{"cell_type":"code","execution_count":96,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["main_basic_df:  24970\n","opinion_df:  113341\n","fee_df:  1988\n","sub_df:  470\n","opinion_flat 113341\n","fee_flat 1988\n","sub_flat 470\n","old_fee_df:  164183\n","old_sub_df:  80323\n","-------------\n","main_basic_df data 0:  Unnamed: 0.1                                                           0\n","Unnamed: 0                                                             0\n","UID                                                                    0\n","JID                                          IPCM,109,刑智上重訴,4,20220127,7\n","court_type                                                     智慧財產及商業法院\n","jud_date                                                        20220127\n","basic_info_20240120                                                  NaN\n","syllabus               \\n原判決撤銷。\\n何建廷、王永銘、聯華電子股份有限公司犯如附表一所示之罪，\\n各處附表一所...\n","jud_full               智慧財產及商業法院刑事判決\\r\\n                             ...\n","jud_url                https://judgment.judicial.gov.tw/FJUD/data.asp...\n","case_num                                                             NaN\n","basic_info                                                           NaN\n","case_type                                                            NaN\n","Name: 0, dtype: object\n","-------------\n"]}],"source":["print('main_basic_df: ', len(main_basic_df))\n","print('opinion_df: ', len(opinion_df))\n","print('fee_df: ', len(fee_df))\n","print('sub_df: ', len(sub_df))\n","print('opinion_flat', opinion_flat.ntotal)\n","print('fee_flat', fee_flat.ntotal)\n","print('sub_flat', sub_flat.ntotal)\n","print('old_fee_df: ', len(old_fee_df))\n","print('old_sub_df: ', len(old_sub_df))\n","print('-------------')\n","print('main_basic_df data 0: ', main_basic_df.iloc[0])\n","print('-------------')\n"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[],"source":["main_basic_df = pd.read_csv('/workspace/111資料/db_loaded/20240228_main_basic.csv')\n"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["66\n"]}],"source":["# main_basic_df.sort_values(by='jud_date', inplace=True)\n","# print(main_basic_df.tail(10))\n","# print(main_basic_df.head(10))\n","# print(len(main_basic_df[main_basic_df['jud_date']>20220531]))\n","print(len(main_basic_df[main_basic_df['jud_date']<=20220103]))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# 20240304_test"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1022154\n","Unnamed: 0                     1022153\n","JID           FYEM,110,豐訴,3,20211230,1\n","sentence                           NaN\n","500                                 無關\n","Name: 1022153, dtype: object\n","If JID are equal True\n"]}],"source":["import pandas as pd\n","\n","# output_csv_path = r\"/workspace/data/CDB_20240304/20240304_predicted/20240304_category_sub.csv\"\n","# prediction_csv_path = r\"/workspace/data/CDB_20240304/110juds_nosimple_paragraph.csv\" #改\n","\n","\n","output_csv_path = r\"/workspace/data/20240304_predicted/20240312_category_sub.csv\"   #改\n","# # prediction_csv_path = r\"/workspace/data/CDB_20240304/110juds_nosimple_sentence.csv\" #改\n","prediction_csv_path = r\"/workspace/data/CDB_20240311/110juds_nosimple_paragraph-no_r&n_0311.csv\" #改\n","\n","\n","df = pd.read_csv(output_csv_path)\n","pdf = pd.read_csv(prediction_csv_path)\n","\n","ckpt_num = '500'\n","print(len(df))\n","print(df.iloc[-1])\n","print('If JID are equal', df['JID'][:len(df)].tolist() == pdf['JID'][:len(df)].tolist())\n","# print(df.iloc[0])\n","# print(pdf.iloc[0])\n","# print(len(df[df[ckpt_num]=='目標']))\n","# print(df[df[ckpt_num]=='目標'].iloc[-1])"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>JID</th>\n","      <th>sentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>291</th>\n","      <td>IPCM,109,刑智上訴,28,20210127,1</td>\n","      <td>│標物品」欄所示之物，沒收</td>\n","    </tr>\n","    <tr>\n","      <th>294</th>\n","      <td>IPCM,109,刑智上訴,28,20210127,1</td>\n","      <td>│標物品」欄所示之物，沒收</td>\n","    </tr>\n","    <tr>\n","      <th>300</th>\n","      <td>IPCM,109,刑智上訴,28,20210127,1</td>\n","      <td>│標物品」欄所示之物，沒收</td>\n","    </tr>\n","    <tr>\n","      <th>2131</th>\n","      <td>TPSM,109,台上,5890,20210107,1</td>\n","      <td>如果上訴理由書狀並未依據卷內訴訟資料，具體指摘原判決不適用何種法則或如何適用不當，或所指摘原...</td>\n","    </tr>\n","    <tr>\n","      <th>2133</th>\n","      <td>TPSM,109,台上,5890,20210107,1</td>\n","      <td>從形式上觀察，並無採證或認定事實違背經驗法則或論理法則，或其他違背法令之情形</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2183497</th>\n","      <td>KSDM,110,簡上,243,20211229,1</td>\n","      <td>三、遷出住居所</td>\n","    </tr>\n","    <tr>\n","      <th>2183498</th>\n","      <td>KSDM,110,簡上,243,20211229,1</td>\n","      <td>五、完成加害人處遇計畫</td>\n","    </tr>\n","    <tr>\n","      <th>2183573</th>\n","      <td>KSDM,110,簡上,264,20211230,1</td>\n","      <td>三、以廣播電視、電子通訊、網際網路或其他媒體等傳播工具，對公眾散布而犯之</td>\n","    </tr>\n","    <tr>\n","      <th>2183773</th>\n","      <td>KSDM,110,簡上,280,20211229,1</td>\n","      <td>三、服用毒品、麻醉藥品或其他相類之物，致不能安全駕駛</td>\n","    </tr>\n","    <tr>\n","      <th>2184325</th>\n","      <td>KSDM,110,訴,29,20211229,1</td>\n","      <td>扣案行動電話壹支（含門號0000000000號SIM卡）沒收</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>24758 rows × 2 columns</p>\n","</div>"],"text/plain":["                                 JID  \\\n","291      IPCM,109,刑智上訴,28,20210127,1   \n","294      IPCM,109,刑智上訴,28,20210127,1   \n","300      IPCM,109,刑智上訴,28,20210127,1   \n","2131     TPSM,109,台上,5890,20210107,1   \n","2133     TPSM,109,台上,5890,20210107,1   \n","...                              ...   \n","2183497   KSDM,110,簡上,243,20211229,1   \n","2183498   KSDM,110,簡上,243,20211229,1   \n","2183573   KSDM,110,簡上,264,20211230,1   \n","2183773   KSDM,110,簡上,280,20211229,1   \n","2184325     KSDM,110,訴,29,20211229,1   \n","\n","                                                  sentence  \n","291                                          │標物品」欄所示之物，沒收  \n","294                                          │標物品」欄所示之物，沒收  \n","300                                          │標物品」欄所示之物，沒收  \n","2131     如果上訴理由書狀並未依據卷內訴訟資料，具體指摘原判決不適用何種法則或如何適用不當，或所指摘原...  \n","2133                從形式上觀察，並無採證或認定事實違背經驗法則或論理法則，或其他違背法令之情形  \n","...                                                    ...  \n","2183497                                            三、遷出住居所  \n","2183498                                        五、完成加害人處遇計畫  \n","2183573               三、以廣播電視、電子通訊、網際網路或其他媒體等傳播工具，對公眾散布而犯之  \n","2183773                         三、服用毒品、麻醉藥品或其他相類之物，致不能安全駕駛  \n","2184325                     扣案行動電話壹支（含門號0000000000號SIM卡）沒收  \n","\n","[24758 rows x 2 columns]"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["tmp_df = pdf[['JID', 'sentence']].copy()\n","tmp_df[tmp_df.duplicated()]"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["526600\n"]}],"source":["# Delete Rows\n","# tdf = df.copy()\n","# tdf.drop(index=tdf[526600:].index, axis=0, inplace=True)\n","# tdf.to_csv('/workspace/data/CDB_20240304/20240304_predicted/20240306_category_opinion.csv', encoding='utf-8-sig', index=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check id and index equal\n","for index, row in df.iterrows():\n","    if index!=row['Unnamed: 0']:\n","        print(index)\n","        break"]},{"cell_type":"markdown","metadata":{},"source":["# 20240304 embedding to text 失敗"]},{"cell_type":"code","execution_count":59,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","def get_mean_pooling_embedding(input_text, tokenizer, model):\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    inputs = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True, return_attention_mask=True, truncation=True, max_length=2048)\n","    inputs = {k:v.to(device) for k,v in inputs.items()}\n","    # print(len(inputs['input_ids'][0]))\n","\n","    with torch.no_grad():\n","        torch.cuda.empty_cache()\n","        gc.collect()\n","        outputs = model(**inputs)\n","    # # # Generating text, leveraging the internal handling of past_key_values\n","    # # output_sequences = model.generate(inputs, max_length=4)\n","\n","    # # # Decode generated text\n","    # # generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n","    # generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    # print(generated_text)\n","    logits = outputs.logits\n","\n","    preds = F.softmax(logits, dim=-1).argmax(dim=-1)\n","    y = tokenizer.batch_decode(sequences=preds, skip_special_tokens=True)\n","    print(y)\n","    # hidden state shape (batch_size, sequence_length, hidden_size)\n","    # (input_tokens_length, 1, 4096)\n","    last_hidden_state = outputs[2][-1]\n","    input_tokens_length = last_hidden_state.shape[0]\n","    # (1, 4096)\n","    embedding = torch.sum(last_hidden_state, 0)\n","    embedding = embedding[0] / input_tokens_length\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return outputs\n","    return embedding"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["已詳敘認定犯罪事實之依據及憑以認定之理由\n"]}],"source":["input_text = '已詳敘認定犯罪事實之依據及憑以認定之理由'\n","# embedding = get_mean_pooling_embedding(input_text, tokenizer, merged_model)\n","# print(embedding)\n","# prediction, history = merged_model.chat(tokenizer, input_text)\n","# print(prediction)\n","\n","# inputs = tokenizer(input_text, return_tensors=\"pt\", add_special_tokens=True, return_attention_mask=True, truncation=True, max_length=2048)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# inputs = {k:v.to(device) for k,v in inputs.items()}\n","\n","input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", add_special_tokens=True, return_attention_mask=True, truncation=True, max_length=2048).to(device)\n","output_sequences = merged_model.generate(input_ids, max_length=1000)\n","generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n","\n","print(generated_text)\n"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["      Unnamed: 0                          JID              sentence 1200\n","1281         168  IPCM,109,刑智上訴,17,20210128,1        ②經政府機關委任有鑑定職務者   目標\n","4361         593   TPSM,109,台上,173,20210113,1                  固非無見   目標\n","6794         981  TPSM,109,台上,3695,20210118,1                  固非無見   目標\n","6835         993  TPSM,109,台上,3695,20210118,1                  始為合憲   目標\n","6992        1030  TPSM,109,台上,3699,20210114,1             且俱有訴訟資料可按   目標\n","12093       1811  TPSM,109,台上,5721,20210113,1                  固非無見   目標\n","16228       2515  TPSM,110,台上,1057,20210127,1  已詳敘認定犯罪事實之依據及憑以認定之理由   目標\n","26250       4194  TPSM,110,台上,1781,20210127,1   已詳細敘述所憑之證據及取捨、認定之理由   目標\n","29576       4797   TPSM,110,台上,256,20210128,1              A女：沒人說過嗎   目標\n","30731       5001   TPSM,110,台上,303,20210113,1  依原判決所確認之事實，其適用法律並無不合   目標\n"]}],"source":["opinion_df = pd.read_csv('/workspace/data/CDB_20240304/20240304_predicted/20240304_category_opinion.csv')\n","opinion_df = opinion_df[opinion_df['1200']=='目標']\n","print(opinion_df.head(10))"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading checkpoint shards: 100%|██████████| 7/7 [00:14<00:00,  2.01s/it]\n","Some weights of ChatGLMForConditionalGeneration were not initialized from the model checkpoint at /workspace/LLM/chatglm2-6b and are newly initialized: ['transformer.prefix_encoder.embedding.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Parameter Merging!\n","Model Quantizationing!\n","Model Loaded!\n","tensor([-1.2119,  2.3086,  5.6523,  ...,  3.1270,  2.1914, -1.8750],\n","       device='cuda:0', dtype=torch.float16)\n"]}],"source":["llm_path = '/workspace/LLM/chatglm2-6b'\n","ckpt_path = '/workspace/data/CDB_20240304/20230620_724td_opinion_-6b-pt-token-1024-3e-3_0818/checkpoint-1200'\n","merged_model = load_glm_checkpoint(ckpt_path, llm_path)\n","tokenizer = AutoTokenizer.from_pretrained(llm_path, trust_remote_code=True)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# 20240320 110juds Merge basic_info and categories"]},{"cell_type":"markdown","metadata":{},"source":["## Load seperate csv files"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import os\n","import re\n","\n","basic_info = pd.read_csv('/workspace/data/CDB_20240304_110juds/20240320_final_merged/20240320_basic_info_110.csv')\n","# dfs = [[csv_path.path, pd.read_csv(csv_path.path)] for csv_path in os.scandir('/workspace/data/CDB_20240304_110juds/20240314_processed')]"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0. 0311_110判決書_無簡_paragraph_ft\n","length: 1022154\n","columns: Index(['Unnamed: 0', 'JID', 'sentence', '450'], dtype='object')\n","---------------\n","1. 0311_110判決書_無簡_paragraph_ft_target\n","length: 35497\n","columns: Index(['Unnamed: 0', 'JID', 'sentence', 'type'], dtype='object')\n","---------------\n","2. 0312_110判決書_無簡_sentence_op\n","length: 2188272\n","columns: Index(['Unnamed: 0', 'JID', 'sentence', '1200'], dtype='object')\n","---------------\n","3. 0312_110判決書_無簡_sentence_op_target\n","length: 364544\n","columns: Index(['Unnamed: 0', 'JID', 'sentence', 'type'], dtype='object')\n","---------------\n","4. 0315_110op_genlabel\n","length: 364544\n","columns: Index(['Unnamed: 0', 'JID', 'sentence', 'type', '600'], dtype='object')\n","---------------\n","5. 110判決書_無簡\n","length: 73637\n","columns: Index(['Unnamed: 0', 'JID', 'JFULL'], dtype='object')\n","---------------\n","6. 110判決書_無簡_case\n","length: 73637\n","columns: Index(['Unnamed: 0', 'JID', 'case_kind'], dtype='object')\n","---------------\n","7. 110判決書_無簡_exacutive\n","length: 73637\n","columns: Index(['Unnamed: 0', 'JID', 'case_kind'], dtype='object')\n","---------------\n","8. 20240312_category_sub_target\n","length: 495427\n","columns: Index(['Unnamed: 0', 'JID', 'sentence', 'type'], dtype='object')\n","---------------\n","9. tar_court_JID\n","length: 73635\n","columns: Index(['Unnamed: 0', 'JID', 'court'], dtype='object')\n","---------------\n","10. tar_court_JID__date\n","length: 73635\n","columns: Index(['Unnamed: 0', 'JID', 'date'], dtype='object')\n","---------------\n"]}],"source":["for df_index, df in enumerate(dfs):\n","    name = os.path.basename(df[0]).split('.csv')[0]\n","    print('{}. {}'.format(df_index, name))\n","    print('length:', len(df[1]))\n","    print('columns:', df[1].columns)\n","    print('---------------')"]},{"cell_type":"code","execution_count":120,"metadata":{},"outputs":[{"data":{"text/plain":["UID                                                       44552\n","JID                                  TNHM,110,上訴,406,20210825,1\n","jud_full      臺灣高等法院臺南分院刑事判決\\r\\n110年度上訴字第406號\\r\\n上  訴  人  \\r...\n","case_num                          臺灣高等法院臺南分院刑事判決\\n110年度上訴字第406號\n","basic_info                          上訴人\\n即被告黃耀陞\\n0\\n法扶律師王明一律師\\n\n","case_type                                         因違反毒品危害防制條例案件\n","court_type                                               臺灣高等法院\n","jud_date                                               20210825\n","jud_url       https://judgment.judicial.gov.tw/FJUD/data.asp...\n","Name: 44552, dtype: object"]},"execution_count":120,"metadata":{},"output_type":"execute_result"}],"source":["# # Rename columns\n","# basic_info.rename(columns={'JFULL':'jud_full', 'Unnamed: 0': 'UID'}, inplace=True)\n","# basic_info.to_csv('/workspace/data/CDB_20240304_110juds/20240320_final_merged/20240320_basic_info_110.csv', encoding='utf-8-sig', index=False)\n","\n","# # Replace colum case_type with case_kind\n","# print('basic_info head', basic_info.iloc[1])\n","# print('6 head', dfs[6][1].iloc[1])\n","\n","# basic_info[['case_type']] = dfs[6][1][['case_kind']]\n","# basic_info.to_csv('/workspace/data/CDB_20240304_110juds/20240320_final_merged/20240320_basic_info_110.csv', encoding='utf-8-sig', index=False)\n","# print(len(basic_info[basic_info['case_num']=='re error']))\n","\n","# # Merge basic_info with jud_date, \n","# court_type = [re.search(r'(.*?法院)', target_column).groups()[0].replace(' ','') for target_column in dfs[5][1]['JFULL']]\n","# jud_date = [target_column.split(',')[4] for target_column in dfs[5][1]['JID']]\n","# jud_url = [f'https://judgment.judicial.gov.tw/FJUD/data.aspx?ty=JD&id={jid}' for jid in basic_info['JID']]\n","# basic_info['jud_url'] = jud_url\n","# basic_info['court_type'] = court_type\n","# basic_info['jud_date'] = jud_date\n","# print(basic_info.iloc[0])\n","# basic_info.to_csv('/workspace/data/CDB_20240304_110juds/20240320_final_merged/20240320_basic_info_110.csv', encoding='utf-8-sig', index=False)\n","\n","# # Add syllabus\n","# basic_info.iloc[44552]\n","\n","\n"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[{"data":{"text/plain":["'https://judgment.judicial.gov.tw/FJUD/data.aspx?ty=JD&id=IPCM,109,刑智上重訴,4,20220127,7'"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv('/workspace/data/111資料/db_loaded/20240306_main_basic.csv', nrows=5)\n","df.iloc[0]\n","df.iloc[0]['jud_url']\n"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"data":{"text/plain":["0"]},"execution_count":106,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["main: TPSM,110,台上,1556,20210506,1, target: TPSM,110,台上,1566,20210527,1\n","27260\n","-------------\n","main: TPSM,110,台上,1556,20210506,1, target: TPSM,110,台上,1566,20210527,1\n","27260\n","-------------\n"]}],"source":["# Compare main_df and target_df JID error\n","main_df_index = 5\n","target_df_index_list = [9, 10]\n","for target_df_index in target_df_index_list:\n","    main_column = dfs[main_df_index][1]['JID'].tolist()\n","    target_df_column = dfs[target_df_index][1]['JID'].tolist()\n","    \n","    for index in range(len(main_column)):\n","        if main_column[index]==target_df_column[index]:\n","            continue\n","        else:\n","            print(f'main: {main_column[index]}, target: {target_df_column[index]}')\n","            print(index)\n","            print('-------------')\n","            break\n"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["73637\n","73637\n","73637\n"]}],"source":["import re\n","\n","JID = dfs[5][1]['JID'].tolist()\n","court_type = [re.search(r'(.*?法院)', target_column).groups()[0].replace(' ','') for target_column in dfs[5][1]['JFULL']]\n","jud_date = [target_column.split(',')[4] for target_column in dfs[5][1]['JID']]\n","\n","basic_info\n","print(len(JID))\n","print(len(court_type))\n","print(len(jud_date))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","\n","\n","# court_type_df = pd.read_csv('/workspace/111資料/111判決書院別/111判決書院別.csv')\n","# jud_date_df = pd.read_csv('/workspace/111資料/111判決書日期/111_date.csv')\n","# # case_kind and basic_info are in same paragraph\n","# basic_info_df = pd.read_csv('/workspace/111資料/111判決書案由與基本資料/data.csv')\n","# syllabus_df = pd.read_csv('/workspace/111資料/111判決書主文及去符號全文/111_main.csv')\n","# jud_full_df = pd.read_csv('/workspace/111資料/111判決書全文_含上級審與地院_有符號與無符號/18個檔案的地院111判決書_無簡_全文_未移除符號.csv')\n","\n","# fee_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_ft_paragraph_district_TARGET.csv')\n","# opinion_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_op_sentence_district_TARGET.csv')\n","# sub_df = pd.read_csv('/workspace/111資料/111判決書提出標註目標/0114_sub_paragraph_district_TARGET.csv')\n","\n","print('court_type_df length:', len(court_type_df))\n","print('court_type_df columns:', court_type_df.columns)\n","print('jud_date_df length:', len(jud_date_df))\n","print('jud_date_df columns:', jud_date_df.columns)\n","print('basic_info_df length:', len(basic_info_df))\n","print('basic_info_df columns:', basic_info_df.columns)\n","print('syllabus_df length:', len(syllabus_df))\n","print('syllabus_df columns:', syllabus_df.columns)\n","print('jud_full_df length:', len(jud_full_df))\n","print('jud_full_df columns:', jud_full_df.columns)\n","\n","print('fee_df columns:', len(fee_df), '\\nfee_df last data index', fee_df.iloc[-1].name)\n","print('opinion_df length:', len(opinion_df), '\\nopinion_df last data index', opinion_df.iloc[-1].name)\n","print('sub_df length:', len(sub_df), '\\nsub_df last data index', sub_df.iloc[-1].name)\n","\n","df_list = [[court_type_df, 'court_type_df'], [basic_info_df, 'basic_info_df'], [syllabus_df,'syllabus_df'], [jud_full_df, 'jud_full_df']] \n","for tmp_list in df_list:\n","    print(f'jud_date_df JID == {tmp_list[1]} JID:', tmp_list[0]['JID'].tolist()==jud_date_df['JID'].tolist())\n","\n","print('Same JID between syllabus_df and jud_date_df:', len(syllabus_df[syllabus_df['JID'].isin(jud_date_df['JID'])]))\n","print('Same JID between syllabus_df and fee_df:', len(syllabus_df[syllabus_df['JID'].isin(fee_df['JID'])]))\n","print('Same JID between syllabus_df and opinion_df:', len(syllabus_df[syllabus_df['JID'].isin(opinion_df['JID'])]))\n","print('Same JID between syllabus_df and sub_df:', len(syllabus_df[syllabus_df['JID'].isin(sub_df['JID'])]))\n","\n","not_in_basic_info = jud_full_df[~jud_full_df['JID'].isin(basic_info_df['JID'])]\n","print('Numbers of JID not in basic_info_df: ', len(not_in_basic_info))\n","# # Check if JID is unique\n","# list(set(fee_df['JID'].tolist()))\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Merge several target columns to main_basic.csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["jud_date_merged = jud_date_df.copy()\n","jud_date_merged = jud_date_merged.merge(basic_info_df[['JID', 'Pair']], on='JID', how='left')\n","# # Check jud_date_merged['Pair] are correctly merged\n","# print('jud_date_merged length: ', len(jud_date_merged))\n","# import random\n","# inbasic = jud_date_merged[jud_date_merged['JID'].isin(basic_info_df['JID'])]\n","# print('inbasic length: ', len(inbasic))\n","# for i in range(20):\n","#     print(inbasic.iloc[random.choice(range(len(inbasic)))])\n","basic_info_list = jud_date_merged['Pair'].tolist()\n","\n","main_basic_df = pd.DataFrame({\n","                              'UID': [data_index for data_index in range(len(jud_date_df))],\n","                              'JID': jud_date_df['JID'].tolist(),\n","                              'court_type': court_type_df['court'].tolist(),\n","                              'jud_date': jud_date_df['date'].tolist(),\n","                              'basic_info': basic_info_list,\n","                              'syllabus': syllabus_df['main'].tolist(),\n","                              'jud_full': jud_full_df['JFULL'].tolist(),\n","                              'jud_url': [f'https://judgment.judicial.gov.tw/FJUD/data.aspx?ty=JD&id={jid}' for jid in jud_date_df['JID']],\n","                              })\n","print('main_basic_df length: ', len(main_basic_df))\n","\n","# # Check main_basic_df is correctly stored\n","for i in range(20):\n","    # print(main_basic_df.iloc[random.choice(range(len(main_basic_df)))])\n","    random_data = main_basic_df.iloc[random.choice(range(len(main_basic_df)))]\n","    print(random_data)\n","    # print(random_data['JID'])\n","    # print(random_data['jud_url'])\n","# # Save DataFrame to csv\n","# main_basic_df.to_csv('/workspace/111資料/20240120_main_basic.csv', encoding='utf-8-sig', index=False)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Add UID to category_csv"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\n","# main_basic_df = pd.read_csv('/workspace/111資料/20240120_main_basic.csv')\n","df_list = [fee_df, opinion_df, sub_df]\n","file_name = ['fee', 'opinion', 'sub']\n","for tmp_index, tmp_df in enumerate(df_list):\n","    \n","    tmp_merged = tmp_df.copy()\n","    tmp_merged = tmp_merged.merge(main_basic_df[['JID', 'UID']], on='JID', how='left')\n","    tmp_merged = tmp_merged.rename(columns={'Unnamed: 0':'EID'})\n","    print('tmp_merged length:', len(tmp_merged))\n","    print('Number of unique JID:', len(list(set(tmp_merged['JID'].tolist()))))\n","    print(\"Number of tmp_merged['UID'] is nan: \", len(tmp_merged[tmp_merged['UID'].isna()]))\n","    print()\n","    tmp_merged.to_csv(f'/workspace/111資料/20240120_category_{file_name[tmp_index]}.csv', encoding='utf-8-sig', index=False)\n","    # # # Check tmp_merged is correctly merged\n","    # for i in range(20):\n","    #     random_data = tmp_merged.iloc[random.choice(range(len(tmp_merged)))]\n","    #     print(random_data)\n","    #     # main_basic_df_tmp = main_basic_df[main_basic_df['JID']==random_data['JID']]\n","    #     # print('main_basic_df_tmp: ', main_basic_df_tmp.iloc[0]['JID'], main_basic_df_tmp.iloc[0]['UID'])\n","    #     # print('random_data', random_data['JID'], random_data['UID'])\n","    #     # print(main_basic_df_tmp.iloc[0]['JID']==random_data['JID'])\n","    #     # print(main_basic_df_tmp.iloc[0]['UID']==random_data['UID'])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Check Saved csv\n","file_name = ['fee', 'opinion', 'sub']\n","for name in file_name:\n","    tmp_df = pd.read_csv(f'/workspace/111資料/20240120_category_{name}.csv')\n","    print(f'File: {name}, Length: {len(tmp_df)}')\n","    print('Unique JID length:', len(list(set(tmp_df['JID'].tolist()))))\n","    print('Unique UID length:', len(list(set(tmp_df['UID'].tolist()))))\n","    print('Unique EID length:', len(list(set(tmp_df['EID'].tolist()))))\n","    print('Last Data:# 20240225 RE basic info \n","import pandas as pd\n","from tqdm import tqdm\n","import re\n","# main_basic_df = pd.read_csv('/workspace/111資料/db_loaded/20240120_main_basic.csv')\n","# main_basic_df = pd.read_csv('/workspace/111資料/db_loaded/20240228_main_basic.csv')\n","main_basic_df = pd.read_csv('/home/lawrencechh/workspace/111資料/db_loaded/20240228_main_basic.csv')\n","print('main_basic_df length:', len(main_basic_df))\n","# nona_df = main_basic_df[~main_basic_df['basic_info_20240120'].isna()]\n","nona_df = main_basic_df.copy()\n","print('nona_df length:', len(nona_df))\n","print()\n","print(nona_df.iloc[0])\n","print(nona_df.iloc[0]['jud_url'])\n","\n","# # 20240305 re jud_full\n","# Get case_num, basic_info, case_type\n","def get_re_multi_matched_list(input_text_list, rule_patterns, remove_special_signs=False):\n","    print('Start get_re_multi_matched_list()')\n","    error_signs = ['\\u3000', '\\u30005', '\\u3000111', '\\u30004', '\\u300011', '\\u30003', '\\u300024', '&nbsp;', '\\u3000110', '\\u300012', '\\u300030', ' ', '\\r']\n","    matched_indices = [[] for _ in range(len(rule_patterns))]\n","    empty_list = []\n","    print('matched_indices', matched_indices)\n","    # ---------------------------\n","    if remove_special_signs:\n","        for input_list_order in range(len(input_text_list)):\n","            input_text = input_text_list[input_list_order][1]\n","            for sign in error_signs:\n","                input_text = input_text.replace(sign, '')\n","            input_text_list[input_list_order][1] = input_text\n","    # ---------------------------\n","    for input_list_order in tqdm(range(len(input_text_list))):\n","        input_text = input_text_list[input_list_order][1]\n","        df_id = input_text_list[input_list_order][0]\n","        for rule_index, pattern in enumerate(rule_patterns):\n","            search_matched = re.search(pattern, input_text, re.DOTALL)\n","            if search_matched:\n","                # search_matched_groups = search_matched.groups()\n","                # length_below_50 = True\n","                # for input_list_order in range(3):\n","                #     if len(search_matched_groups[input_list_order]) > 50:\n","                #         length_below_50 = False\n","                #         break\n","                # if length_below_50:\n","                #     matched_indices[rule_index].append([df_id, search_matched])\n","                #     break\n","                matched_indices[rule_index].append([input_list_order, df_id, search_matched.groups(), [len(group) for group in search_matched.groups()]])\n","                break\n","\n","        if not search_matched:\n","            empty_list.append([input_list_order, df_id, input_text])\n","    matched_length = [len(matched) for matched in matched_indices]\n","    print('matched:', matched_length)\n","    print('empty:', len(empty_list))\n","    return [matched_indices, empty_list]\n","\n","input_texts = [[index, row['jud_full'][:4000]] for index, row in nona_df.iterrows()]\n","result_list = get_re_multi_matched_list(input_texts, [r'(.+?)主 *?文'], True)\n","input_texts = [[df_id, re_text[0]] for _, df_id, re_text, _ in result_list[0][0]]\n","basic_info_patterns = [\n","        r'(.+?第\\d+號)\\n(.+?)上列.+?因(.+?)[（|、|，]',\n","        r'(.+?號)\\n([上訴人|聲請人|公訴人|自訴人].+?)[上|上列|以上|下列].+?因(.+?)[（|、|，]',\n","        r'(.+?第\\d+號)\\n?(.+?)[上|上列|以上|下列].+?因(.+?)[（|、|，]',\n","        r'(.+?)\\n([上訴人|聲請人|公訴人|自訴人].+)\\n(.+?案件)',\n","]\n","result_list = get_re_multi_matched_list(input_texts, basic_info_patterns, False)\n","\n","\n","\n","\n","# Check empty list\n","count = 0\n","matched_list = []\n","empty_list = []\n","for text in result_list[1]:\n","    \n","    # input_text = text[1].replace('\\n', '')\n","    input_text = text[2]\n","\n","    # matched = re.search(r'(.+?)\\n([上訴人|聲請人|公訴人|自訴人].+?)[上|上列|以上|下列].+?因(.+?)[（|、|，]', input_text, re.DOTALL)\n","    matched = re.search(r'(.+?)\\n([上訴人|聲請人|公訴人|自訴人].+)\\n(.+?案件)', input_text, re.DOTALL)\n","    \n","    if matched:\n","        matched_list.append(matched)\n","        # print(text)\n","\n","        print(matched.groups())\n","    else:\n","        print(text)\n","        empty_list.append(text)\n","    count+=1\n","    if count>50:\n","        break\n","\n","# print(matched_list)\n","print('matched_list length: ', len(matched_list))\n","# print(empty_list)\n","print('empty_list length: ', len(empty_list))\n","# Show result according to rule_index and group_index\n","rule_index = 0\n","group_index = 1\n","group_length = 3\n","rule_length = len(result_list[0])\n","\n","sorted_result = []\n","for rule_index in range(rule_length):\n","    sorted_result.append([])\n","    for group_index in range(group_length):\n","        sorted_result[rule_index].append([])\n","        sorted_result[rule_index][group_index] = sorted(result_list[0][rule_index], key=lambda x: x[3][group_index], reverse=True)\n","        try:\n","            print(f'rule_index:{rule_index}, group_index:{group_index}, {sorted_result[rule_index][group_index][0][3][group_index]}')\n","            print(f'Data 0: {sorted_result[rule_index][group_index][0]}')\n","        except:\n","            continue\n","# Show input_text according to index\n","input_text_index = 23575\n","print([input_texts[input_text_index]])\n","test = '公訴人臺灣臺北地方檢察署檢察官\\n被告林峻吉\\n\\n\\n\\n選任辯護人謝文郡律師\\n劉衡慶律師\\n被告林奇賢\\n\\n\\n\\n選任辯護人林芸律師\\n彭成翔律師（法扶律師）\\n陳稚婷律師（法扶律師）\\n被告王端彬\\n\\n\\n\\n\\n\\n選任辯護人賴成維律師\\n陳昱龍律師（法扶律師）\\n被告陳展鑫\\n\\n\\n\\n\\n選任辯護人邱俊傑律師（法扶律師）\\n被告李嘉銘\\n\\n\\n\\n選任辯護人楊愛基律師（法扶律師）\\n被告魏敏峰\\n\\n\\n\\n選任辯護人李弘仁律師（法扶律師）\\n被告謝佳弘\\n\\n\\n\\n\\n選任辯護人張智超律師（法扶律師）\\n被告曾台儒\\n\\n\\n選任辯護人蘇彥文律師（法扶律師）\\n被告王繹閔\\n\\n\\n\\n\\n選任辯護人林世昌律師（法扶律師）\\n被告藺煥宇\\n\\n\\n選任辯護人翟世炎律師（法扶律師）'\n","test = re.sub(r'\\n+', '\\n', test)\n","print(test)\n","# Store new csv according to original csv copy\n","output_basic_df = main_basic_df.copy()\n","for rule_list in result_list[0]:\n","    print('rule_list:', len(rule_list))\n","    for data in rule_list:\n","        df_index = data[1]\n","        case_num = data[2][0]\n","        basic_info = re.sub(r'\\n+', '\\n', data[2][1])\n","        case_type = data[2][2]\n","        new_data_dict = {'case_num': case_num, 'basic_info': basic_info, 'case_type': case_type}\n","\n","        for key, value in new_data_dict.items():\n","            output_basic_df.loc[df_index, key] = value\n","# output_basic_df.to_csv('/workspace/111資料/db_loaded/20240306_main_basic.csv', encoding='utf-8-sig', index=False)\n","output_basic_df.to_csv('/home/lawrencechh/workspace/111資料/db_loaded/20240306_main_basic.csv', encoding='utf-8-sig', index=False)\n","# output_basic_df.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1, inplace=True)\n","output_basic_df.iloc[-1]\n","output_basic_df.to_csv('/home/lawrencechh/workspace/111資料/db_loaded/20240306_main_basic.csv', encoding='utf-8-sig', index=False)\n","\n","# Check output data\n","main_basic_df = pd.read_csv('/home/lawrencechh/workspace/111資料/db_loaded/20240306_main_basic.csv')\n","# main_basic_df = pd.read_csv('/home/lawrencechh/workspace/111資料/db_loaded/20240228_main_basic.csv')\n","import random\n","print(len(main_basic_df))\n","for i in range(10):\n","    print(main_basic_df.iloc[random.choice(range(len(main_basic_df)))])\n","    print('----------------------')\n","\\n')\n","    print(tmp_df.iloc[-1])\n","    print()\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"chatglm_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":0}
